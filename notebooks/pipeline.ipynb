{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86858a9",
   "metadata": {},
   "source": [
    "# Corporate Credit Early Warning System (EWS)\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "H·ªá th·ªëng c·∫£nh b√°o s·ªõm r·ªßi ro t√≠n d·ª•ng doanh nghi·ªáp (Corporate Credit EWS) ƒë∆∞·ª£c x√¢y d·ª±ng theo chu·∫©n Basel, s·ª≠ d·ª•ng Machine Learning ƒë·ªÉ d·ª± ƒëo√°n x√°c su·∫•t v·ª° n·ª£ (PD - Probability of Default) trong v√≤ng 12 th√°ng t·ªõi.\n",
    "\n",
    "**M·ª•c ti√™u ch√≠nh:**\n",
    "- D·ª± ƒëo√°n kh·∫£ nƒÉng v·ª° n·ª£ c·ªßa kh√°ch h√†ng doanh nghi·ªáp (event horizon: 12 th√°ng)\n",
    "- Ph√¢n lo·∫°i r·ªßi ro th√†nh 3 tiers: **Green** (an to√†n), **Amber** (c·∫£nh b√°o), **Red** (nguy hi·ªÉm)\n",
    "- ƒê∆∞a ra khuy·∫øn ngh·ªã h√†nh ƒë·ªông c·ª• th·ªÉ cho Risk Management team\n",
    "\n",
    "**Tech Stack:**\n",
    "- Python 3.13\n",
    "- LightGBM (classification model)\n",
    "- SHAP (model explainability)\n",
    "- Sklearn (calibration, metrics)\n",
    "- Pandas/Numpy (data processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f0cf4",
   "metadata": {},
   "source": [
    "## Pipeline Architecture\n",
    "\n",
    "D·ª± √°n ƒë∆∞·ª£c t·ªï ch·ª©c theo **end-to-end ML pipeline** v·ªõi 7 b∆∞·ªõc ch√≠nh:\n",
    "\n",
    "```\n",
    "1. Data Generation (generate_data.py)\n",
    "   ‚Üì\n",
    "2. Feature Engineering (feature_engineering.py)\n",
    "   ‚Üì\n",
    "3. Model Training + Calibration (train_baseline.py)\n",
    "   ‚Üì\n",
    "4. Model Explainability (explain.py)\n",
    "   ‚Üì\n",
    "5. [Optional] Make Raw Scores (make_scores_raw.py)\n",
    "   ‚Üì\n",
    "6. [Optional] Re-calibration (calibrate.py)\n",
    "   ‚Üì\n",
    "7. Production Scoring (scoring.py)\n",
    "```\n",
    "\n",
    "### Data Flow\n",
    "- **Raw Data** ‚Üí `data/raw/` (fin_quarterly, credit_daily, cashflow_daily, covenant, labels)\n",
    "- **Features** ‚Üí `data/processed/` (feature_ews.parquet)\n",
    "- **Models** ‚Üí `artifacts/models/` (model_lgbm.pkl, SHAP artifacts)\n",
    "- **Scores** ‚Üí `artifacts/scoring/` (ews_scored_YYYY-MM-DD.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fd11a",
   "metadata": {},
   "source": [
    "## Step 1: Data Generation\n",
    "\n",
    "Module: `src/generate_data.py`\n",
    "\n",
    "### M·ª•c ƒë√≠ch\n",
    "\n",
    "T·∫°o d·ªØ li·ªáu synthetic ƒë·ªÉ train PD model khi ch∆∞a c√≥ d·ªØ li·ªáu th·∫≠t t·ª´ ng√¢n h√†ng. D·ªØ li·ªáu ƒë∆∞·ª£c thi·∫øt k·∫ø s√°t th·ª±c t·∫ø nghi·ªáp v·ª• corporate lending v√† tu√¢n th·ªß Basel principles.\n",
    "\n",
    "**L√Ω do d√πng Synthetic Data:**\n",
    "- ‚úÖ Tr√°nh v·∫•n ƒë·ªÅ b·∫£o m·∫≠t v√† compliance v·ªõi d·ªØ li·ªáu n·ªôi b·ªô\n",
    "- ‚úÖ C√≥ ground truth ch√≠nh x√°c (bi·∫øt ch·∫Øc ai default) ƒë·ªÉ ƒë√°nh gi√° model\n",
    "- ‚úÖ Scale d·ªÖ d√†ng (1K, 10K, 100K customers) cho stress testing\n",
    "- ‚úÖ T·∫°o edge cases hi·∫øm g·∫∑p trong reality (severe stress scenarios)\n",
    "- ‚ùå H·∫°n ch·∫ø: Distribution shift so v·ªõi d·ªØ li·ªáu th·∫≠t ‚Üí Model c·∫ßn retrain khi deploy production\n",
    "\n",
    "---\n",
    "\n",
    "### C·∫•u h√¨nh Portfolio\n",
    "\n",
    "**10 Sectors** v·ªõi risk premiums kh√°c nhau:\n",
    "- Low risk: IT (-0.02), Telecom (-0.01), Engineering/Manufacturing (0.0)\n",
    "- Medium: Chemicals/Logistics (0.02), Retail/Construction (0.03)\n",
    "- Higher risk: Agriculture (0.04), Trading (0.05)\n",
    "\n",
    "**2 Size buckets:**\n",
    "- **SME (80%)**: Revenue ~40K/quarter, Debt multiplier 1.2, higher default risk\n",
    "- **Corp (20%)**: Revenue ~110K/quarter, Debt multiplier 1.4, more leverage but stable\n",
    "\n",
    "‚Üí Total: 1000 customers (800 SMEs + 200 Corps)\n",
    "\n",
    "---\n",
    "\n",
    "### D·ªØ li·ªáu ƒë∆∞·ª£c t·∫°o\n",
    "\n",
    "**1. fin_quarterly.parquet** - B√°o c√°o t√†i ch√≠nh quarterly\n",
    "\n",
    "12 quarters (3 years history ƒë·∫øn 2025-06-30) √ó 1000 customers = 12,000 rows\n",
    "\n",
    "Key columns: `revenue`, `ebitda`, `ebit`, `interest_expense`, `total_debt`, `current_assets`, `current_liab`, `ar`, `ap`, `inventory`\n",
    "\n",
    "Logic:\n",
    "- Revenue growth ~2% QoQ + noise\n",
    "- EBITDA margin ~15% ¬± 7%\n",
    "- Debt = Revenue √ó (0.3 + sector_risk) √ó size_multiplier\n",
    "- Working capital items (AR, AP, Inventory) theo industry standards\n",
    "\n",
    "---\n",
    "\n",
    "**2. credit_daily.parquet** - H√†nh vi t√≠n d·ª•ng h√†ng ng√†y\n",
    "\n",
    "545 days (180 days observation + 365 days label window) √ó 1000 = 545,000 rows\n",
    "\n",
    "Key columns: `limit`, `utilized`, `dpd_days`, `breach_flag`, `product_type`\n",
    "\n",
    "**DPD Dynamics** (Days Past Due):\n",
    "- Markov chain: 98.5% stable/improve, 1.5% deteriorate\n",
    "- Majority < 30 days, some 30-90, few > 90\n",
    "- Persistent DPD ‚â• 90 for ‚â• 30 consecutive days ‚Üí Default\n",
    "\n",
    "**Utilization Pattern:**\n",
    "- Beta distribution (centered ~50%) + seasonality (¬±5%) + noise\n",
    "- High utilization (>90%) = stress signal\n",
    "\n",
    "---\n",
    "\n",
    "**3. cashflow_daily.parquet** - D√≤ng ti·ªÅn h√†ng ng√†y\n",
    "\n",
    "545 days √ó 1000 = 545,000 rows\n",
    "\n",
    "Key columns: `inflow`, `outflow`\n",
    "\n",
    "Logic:\n",
    "- Daily inflow = Annual revenue / 365 √ó seasonality √ó noise\n",
    "- Daily outflow = ~90% of inflow √ó noise\n",
    "- Seasonality: Sin wave v·ªõi amplitude 20%\n",
    "\n",
    "Use cases: Detect revenue drops, burn rate, cashflow volatility\n",
    "\n",
    "---\n",
    "\n",
    "**4. covenant.parquet** - Covenant compliance tracking\n",
    "\n",
    "545 days √ó 1000 = 545,000 rows\n",
    "\n",
    "Key covenants:\n",
    "- **ICR** (Interest Coverage Ratio): EBIT / Interest ‚â• 1.5\n",
    "- **DSCR** (Debt Service Coverage Ratio): Cashflow / Debt service ‚â• 1.2\n",
    "- **Leverage**: Debt / EBITDA ‚â§ 4.0\n",
    "\n",
    "Breach flags: `breach_icr`, `breach_dscr`, `breach_leverage`\n",
    "\n",
    "---\n",
    "\n",
    "**5. labels.parquet** - Target variable\n",
    "\n",
    "1000 rows (1 per customer at asof_date = 2025-06-30)\n",
    "\n",
    "**Label Definition** (Basel-compliant):\n",
    "```python\n",
    "event_h12m = 1 if DPD ‚â• 90 for ‚â• 30 consecutive days trong 12 th√°ng sau asof_date\n",
    "           = 0 otherwise\n",
    "```\n",
    "\n",
    "**PD Bumps** (tƒÉng default probability):\n",
    "- High utilization (>90%) ‚Üí +20% PD\n",
    "- Covenant breach ‚Üí +20% PD\n",
    "\n",
    "Expected default rate: **~5-10%** (realistic cho corporate portfolio)\n",
    "\n",
    "---\n",
    "\n",
    "### Output Structure\n",
    "\n",
    "```\n",
    "data/raw/\n",
    "‚îú‚îÄ‚îÄ fin_quarterly.parquet       # 12K rows - Financial statements\n",
    "‚îú‚îÄ‚îÄ credit_daily.parquet        # 545K rows - Credit behavior\n",
    "‚îú‚îÄ‚îÄ cashflow_daily.parquet      # 545K rows - Cash movements\n",
    "‚îú‚îÄ‚îÄ covenant.parquet            # 545K rows - Covenant tracking\n",
    "‚îî‚îÄ‚îÄ labels.parquet              # 1K rows - Default labels\n",
    "```\n",
    "\n",
    "File sizes: ~5-10 MB total (Parquet compressed)\n",
    "\n",
    "---\n",
    "\n",
    "### Realism Features\n",
    "\n",
    "‚úÖ **Financial ratios** follow industry norms (EBITDA margin 15%, Debt/Revenue 0.3-0.6)  \n",
    "‚úÖ **DPD patterns** realistic (gradual deterioration, kh√¥ng ƒë·ªôt ng·ªôt 0 ‚Üí 90)  \n",
    "‚úÖ **Seasonality** trong revenue v√† cashflow (quarterly peaks)  \n",
    "‚úÖ **Covenant breaches** trigger increased default risk  \n",
    "‚úÖ **Working capital** (DSO ~66 days, DPO ~73 days) theo industry benchmarks\n",
    "\n",
    "‚Üí Model trained tr√™n data n√†y h·ªçc ƒë∆∞·ª£c patterns g·∫ßn v·ªõi reality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac84d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate synthetic data v√† verify k·∫øt qu·∫£\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1: GENERATE SYNTHETIC DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Command ƒë·ªÉ generate data\n",
    "print(\"\\nüìù Command to generate data:\")\n",
    "print(\"python src/generate_data.py --n-customers 1000 --output-dir data/raw\")\n",
    "\n",
    "print(\"\\nüìä Expected outputs:\")\n",
    "outputs = {\n",
    "    \"fin_quarterly.parquet\": \"~12,000 rows (1000 customers √ó 12 quarters)\",\n",
    "    \"credit_daily.parquet\": \"~545,000 rows (1000 customers √ó 545 days)\",\n",
    "    \"cashflow_daily.parquet\": \"~545,000 rows (1000 customers √ó 545 days)\",\n",
    "    \"covenant.parquet\": \"~545,000 rows (1000 customers √ó 545 days)\",\n",
    "    \"labels.parquet\": \"1,000 rows (1 row per customer)\"\n",
    "}\n",
    "\n",
    "for file, desc in outputs.items():\n",
    "    print(f\"  ‚úì data/raw/{file:30s} ‚Üí {desc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFICATION AFTER GENERATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# N·∫øu data ƒë√£ t·ªìn t·∫°i, verify n√≥\n",
    "data_dir = \"../data/raw\"\n",
    "if os.path.exists(data_dir):\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        \n",
    "        print(\"\\n‚úÖ Data directory found! Checking files...\")\n",
    "        \n",
    "        # Check labels\n",
    "        labels_path = f\"{data_dir}/labels.parquet\"\n",
    "        if os.path.exists(labels_path):\n",
    "            labels = pd.read_parquet(labels_path)\n",
    "            default_rate = labels['event_h12m'].mean()\n",
    "            print(f\"\\nüìå labels.parquet:\")\n",
    "            print(f\"   - Total customers: {len(labels):,}\")\n",
    "            print(f\"   - Default rate (event_h12m=1): {default_rate:.1%}\")\n",
    "            print(f\"   - Expected: 5-10% ‚úì\" if 0.05 <= default_rate <= 0.15 else \"   - Warning: Outside expected range\")\n",
    "        \n",
    "        # Check credit_daily\n",
    "        credit_path = f\"{data_dir}/credit_daily.parquet\"\n",
    "        if os.path.exists(credit_path):\n",
    "            credit = pd.read_parquet(credit_path)\n",
    "            print(f\"\\nüìå credit_daily.parquet:\")\n",
    "            print(f\"   - Total rows: {len(credit):,}\")\n",
    "            print(f\"   - Date range: {credit['date'].min()} to {credit['date'].max()}\")\n",
    "            print(f\"   - Max DPD: {credit['dpd_days'].max()} days\")\n",
    "            print(f\"   - Breach rate: {credit['breach_flag'].mean():.1%}\")\n",
    "            print(f\"   - Avg utilization: {(credit['utilized']/credit['limit']).mean():.1%}\")\n",
    "        \n",
    "        # Check fin_quarterly\n",
    "        fin_path = f\"{data_dir}/fin_quarterly.parquet\"\n",
    "        if os.path.exists(fin_path):\n",
    "            fin = pd.read_parquet(fin_path)\n",
    "            print(f\"\\nüìå fin_quarterly.parquet:\")\n",
    "            print(f\"   - Total rows: {len(fin):,}\")\n",
    "            print(f\"   - Unique customers: {fin['customer_id'].nunique():,}\")\n",
    "            print(f\"   - Quarters: {fin['fq_date'].nunique()}\")\n",
    "            print(f\"   - Avg EBITDA margin: {(fin['ebitda']/fin['revenue']).mean():.1%}\")\n",
    "            print(f\"   - Avg Debt/EBITDA: {(fin['total_debt']/fin['ebitda']).mean():.1f}x\")\n",
    "        \n",
    "        print(\"\\n‚úÖ All checks passed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  Could not verify data: {e}\")\n",
    "        print(\"   Run the generate_data.py script first to create the data.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Data directory not found: {data_dir}\")\n",
    "    print(\"   Run the following command to generate data:\")\n",
    "    print(\"   python src/generate_data.py --n-customers 1000 --output-dir data/raw\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c495f97",
   "metadata": {},
   "source": [
    "## üîß Step 2: Feature Engineering\n",
    "\n",
    "Module: `src/feature_engineering.py`\n",
    "\n",
    "### Overview\n",
    "\n",
    "Feature Engineering l√† b∆∞·ªõc quan tr·ªçng nh·∫•t trong vi·ªác x√¢y d·ª±ng m√¥ h√¨nh Early Warning System, v√¨ n√≥ chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√¥ t·ª´ c√°c b·∫£ng t√†i ch√≠nh, h√†nh vi t√≠n d·ª•ng, v√† d√≤ng ti·ªÅn th√†nh c√°c ƒë·∫∑c tr∆∞ng (features) c√≥ s·ª©c m·∫°nh d·ª± ƒëo√°n cao. Qu√° tr√¨nh n√†y k·∫øt h·ª£p ki·∫øn th·ª©c chuy√™n m√¥n v·ªÅ t√≠n d·ª•ng ng√¢n h√†ng v·ªõi k·ªπ thu·∫≠t ph√¢n t√≠ch d·ªØ li·ªáu, t·∫°o ra t·∫≠p h·ª£p c√°c ch·ªâ s·ªë ph·∫£n √°nh ƒë·∫ßy ƒë·ªß t√¨nh h√¨nh t√†i ch√≠nh v√† r·ªßi ro c·ªßa kh√°ch h√†ng doanh nghi·ªáp.\n",
    "\n",
    "C√°c features ƒë∆∞·ª£c thi·∫øt k·∫ø d·ª±a tr√™n c√°c nguy√™n t·∫Øc Basel v√† th·ª±c ti·ªÖn qu·∫£n l√Ω r·ªßi ro t√≠n d·ª•ng, chia th√†nh 5 nh√≥m ch√≠nh: Financial Ratios, Behavioral Features, Cashflow Features, Covenant Breach Flags, v√† Normalization. M·ªói nh√≥m ph·ª•c v·ª• m·ªôt m·ª•c ƒë√≠ch c·ª• th·ªÉ trong vi·ªác ƒë√°nh gi√° kh·∫£ nƒÉng v·ª° n·ª£ c·ªßa kh√°ch h√†ng.\n",
    "\n",
    "---\n",
    "\n",
    "### A. Financial Ratios (TTM - Trailing 12 Months)\n",
    "\n",
    "C√°c t·ª∑ s·ªë t√†i ch√≠nh ƒë∆∞·ª£c t√≠nh to√°n d·ª±a tr√™n d·ªØ li·ªáu 12 th√°ng g·∫ßn nh·∫•t (TTM) ƒë·ªÉ ph·∫£n √°nh xu h∆∞·ªõng d√†i h·∫°n v√† gi·∫£m thi·ªÉu ·∫£nh h∆∞·ªüng c·ªßa bi·∫øn ƒë·ªông ng·∫Øn h·∫°n. Ch√∫ng ta s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ 4 qu√Ω g·∫ßn nh·∫•t ƒë·ªÉ t√≠nh to√°n c√°c ch·ªâ s·ªë t·ªïng h·ª£p n√†y.\n",
    "\n",
    "#### Liquidity & Coverage Ratios\n",
    "\n",
    "**Interest Coverage Ratio (ICR)** l√† ch·ªâ s·ªë quan tr·ªçng nh·∫•t trong ƒë√°nh gi√° kh·∫£ nƒÉng tr·∫£ n·ª£, ƒë∆∞·ª£c t√≠nh b·∫±ng EBIT chia cho chi ph√≠ l√£i vay (Interest Expense). \n",
    "\n",
    "$$\\text{ICR} = \\frac{\\text{EBIT}_{\\text{TTM}}}{\\text{Interest Expense}_{\\text{TTM}}}$$\n",
    "\n",
    "T·ª∑ s·ªë n√†y ƒëo l∆∞·ªùng kh·∫£ nƒÉng c·ªßa doanh nghi·ªáp trong vi·ªác tr·∫£ l√£i vay t·ª´ l·ª£i nhu·∫≠n ho·∫°t ƒë·ªông. Theo th√¥ng l·ªá ng√†nh ng√¢n h√†ng, ICR d∆∞·ªõi 1.5 ƒë∆∞·ª£c coi l√† m·ª©c nguy hi·ªÉm, cho th·∫•y doanh nghi·ªáp kh√¥ng ƒë·ªß kh·∫£ nƒÉng trang tr·∫£i nghƒ©a v·ª• l√£i vay t·ª´ thu nh·∫≠p ho·∫°t ƒë·ªông.\n",
    "\n",
    "**Debt Service Coverage Ratio (DSCR)** ƒëo l∆∞·ªùng kh·∫£ nƒÉng tr·∫£ c·∫£ n·ª£ g·ªëc v√† l√£i t·ª´ EBITDA sau khi tr·ª´ ƒëi chi ph√≠ v·ªën (CAPEX). \n",
    "\n",
    "$$\\text{DSCR} = \\frac{\\text{EBITDA} - \\text{CAPEX}}{\\text{Principal} + \\text{Interest}}$$\n",
    "\n",
    "Do d·ªØ li·ªáu synthetic kh√¥ng c√≥ th√¥ng tin chi ti·∫øt v·ªÅ kho·∫£n tr·∫£ n·ª£ g·ªëc, ch√∫ng ta s·ª≠ d·ª•ng proxy b·∫±ng c√°ch ∆∞·ªõc t√≠nh CAPEX l√† 30% c·ªßa EBITDA. DSCR d∆∞·ªõi 1.2 cho th·∫•y doanh nghi·ªáp g·∫∑p kh√≥ khƒÉn trong vi·ªác ƒë√°p ·ª©ng c√°c nghƒ©a v·ª• n·ª£.\n",
    "\n",
    "**Current Ratio** ph·∫£n √°nh thanh kho·∫£n ng·∫Øn h·∫°n, ƒë∆∞·ª£c t√≠nh b·∫±ng t√†i s·∫£n ng·∫Øn h·∫°n (Current Assets) chia cho n·ª£ ng·∫Øn h·∫°n (Current Liabilities). \n",
    "\n",
    "$$\\text{Current Ratio} = \\frac{\\text{Current Assets}}{\\text{Current Liabilities}}$$\n",
    "\n",
    "T·ª∑ s·ªë n√†y cho bi·∫øt kh·∫£ nƒÉng c·ªßa doanh nghi·ªáp trong vi·ªác thanh to√°n c√°c kho·∫£n n·ª£ ƒë·∫øn h·∫°n trong v√≤ng 12 th√°ng t·ªõi. Current Ratio d∆∞·ªõi 1.0 l√† d·∫•u hi·ªáu c·∫£nh b√°o thi·∫øu thanh kho·∫£n nghi√™m tr·ªçng.\n",
    "\n",
    "#### Leverage Ratio\n",
    "\n",
    "**Debt-to-EBITDA** ƒëo l∆∞·ªùng ƒë√≤n b·∫©y t√†i ch√≠nh, cho bi·∫øt doanh nghi·ªáp c·∫ßn bao nhi√™u nƒÉm EBITDA ƒë·ªÉ tr·∫£ h·∫øt n·ª£. \n",
    "\n",
    "$$\\text{Debt-to-EBITDA} = \\frac{\\text{Total Debt}}{\\text{EBITDA}_{\\text{TTM}}}$$\n",
    "\n",
    "T·ª∑ s·ªë n√†y ƒë∆∞·ª£c t√≠nh b·∫±ng t·ªïng n·ª£ (Total Debt) chia cho EBITDA TTM. Theo chu·∫©n m·ª±c ng√†nh, Debt-to-EBITDA v∆∞·ª£t qu√° 4.0 cho th·∫•y doanh nghi·ªáp ƒëang ch·ªãu g√°nh n·∫∑ng n·ª£ qu√° m·ª©c, l√†m tƒÉng ƒë√°ng k·ªÉ r·ªßi ro v·ª° n·ª£.\n",
    "\n",
    "#### Working Capital Efficiency\n",
    "\n",
    "Nh√≥m ch·ªâ s·ªë n√†y ƒë√°nh gi√° hi·ªáu qu·∫£ qu·∫£n l√Ω v·ªën l∆∞u ƒë·ªông th√¥ng qua ba th√†nh ph·∫ßn ch√≠nh:\n",
    "\n",
    "**Days Sales Outstanding (DSO)** ƒëo l∆∞·ªùng s·ªë ng√†y trung b√¨nh ƒë·ªÉ thu h·ªìi ti·ªÅn t·ª´ kh√°ch h√†ng:\n",
    "\n",
    "$$\\text{DSO} = \\frac{\\text{Accounts Receivable}}{\\text{Revenue}} \\times 365$$\n",
    "\n",
    "DSO tƒÉng cao cho th·∫•y doanh nghi·ªáp g·∫∑p kh√≥ khƒÉn trong vi·ªác thu h·ªìi c√¥ng n·ª£, c√≥ th·ªÉ d·∫´n ƒë·∫øn thi·∫øu h·ª•t ti·ªÅn m·∫∑t.\n",
    "\n",
    "**Days Payables Outstanding (DPO)** ƒëo l∆∞·ªùng s·ªë ng√†y trung b√¨nh doanh nghi·ªáp tr·∫£ ti·ªÅn cho nh√† cung c·∫•p:\n",
    "\n",
    "$$\\text{DPO} = \\frac{\\text{Accounts Payable}}{\\text{COGS}} \\times 365$$\n",
    "\n",
    "DPO cao c√≥ th·ªÉ l√† d·∫•u hi·ªáu t√≠ch c·ª±c (t·∫≠n d·ª•ng t√≠n d·ª•ng th∆∞∆°ng m·∫°i) ho·∫∑c ti√™u c·ª±c (kh√≥ khƒÉn thanh kho·∫£n).\n",
    "\n",
    "**Days On Hand (DOH)** ƒëo l∆∞·ªùng s·ªë ng√†y t·ªìn kho trung b√¨nh:\n",
    "\n",
    "$$\\text{DOH} = \\frac{\\text{Inventory}}{\\text{COGS}} \\times 365$$\n",
    "\n",
    "DOH cao cho th·∫•y h√†ng t·ªìn kho nhi·ªÅu, c√≥ th·ªÉ l√†m gi√°n ƒëo·∫°n d√≤ng ti·ªÅn.\n",
    "\n",
    "**Cash Conversion Cycle (CCC)** l√† ch·ªâ s·ªë t·ªïng h·ª£p:\n",
    "\n",
    "$$\\text{CCC} = \\text{DSO} + \\text{DOH} - \\text{DPO}$$\n",
    "\n",
    "CCC ƒëo l∆∞·ªùng s·ªë ng√†y v·ªën b·ªã \"ƒë√≥ng bƒÉng\" trong chu k·ª≥ kinh doanh, t·ª´ khi tr·∫£ ti·ªÅn mua h√†ng ƒë·∫øn khi thu ƒë∆∞·ª£c ti·ªÅn t·ª´ kh√°ch h√†ng. CCC tƒÉng cao cho th·∫•y hi·ªáu qu·∫£ qu·∫£n l√Ω v·ªën l∆∞u ƒë·ªông k√©m, l√†m d√≤ng ti·ªÅn x·∫•u ƒëi.\n",
    "\n",
    "#### Trend Analysis (QoQ)\n",
    "\n",
    "Ngo√†i c√°c ch·ªâ s·ªë tƒ©nh, ch√∫ng ta c√≤n t√≠nh to√°n xu h∆∞·ªõng thay ƒë·ªïi theo qu√Ω (Quarter-over-Quarter) cho c√°c ch·ªâ s·ªë quan tr·ªçng:\n",
    "\n",
    "$$\\Delta \\text{DSO}_{\\text{QoQ}} = \\text{DSO}_{\\text{current}} - \\text{DSO}_{\\text{previous quarter}}$$\n",
    "\n",
    "$$\\Delta \\text{CCC}_{\\text{QoQ}} = \\text{CCC}_{\\text{current}} - \\text{CCC}_{\\text{previous quarter}}$$\n",
    "\n",
    "**delta_dso_qoq** v√† **delta_ccc_qoq** cho bi·∫øt s·ª± thay ƒë·ªïi c·ªßa DSO v√† CCC so v·ªõi qu√Ω tr∆∞·ªõc, gi√∫p ph√°t hi·ªán s·ªõm c√°c d·∫•u hi·ªáu x·∫•u ƒëi trong qu·∫£n l√Ω v·ªën l∆∞u ƒë·ªông."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef4b2b8",
   "metadata": {},
   "source": [
    "### B. Behavioral Features (Observation Window = 180 ng√†y)\n",
    "\n",
    "C√°c ƒë·∫∑c tr∆∞ng h√†nh vi ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ d·ªØ li·ªáu giao d·ªãch h√†ng ng√†y trong 180 ng√†y g·∫ßn nh·∫•t tr∆∞·ªõc ng√†y ƒë√°nh gi√° (as-of date). Nh·ªØng features n√†y ph·∫£n √°nh h√†nh vi s·ª≠ d·ª•ng t√≠n d·ª•ng th·ª±c t·∫ø c·ªßa kh√°ch h√†ng, th∆∞·ªùng c√≥ s·ª©c m·∫°nh d·ª± ƒëo√°n cao h∆°n so v·ªõi c√°c ch·ªâ s·ªë t√†i ch√≠nh truy·ªÅn th·ªëng v√¨ ch√∫ng n·∫Øm b·∫Øt ƒë∆∞·ª£c c√°c v·∫•n ƒë·ªÅ thanh kho·∫£n v√† kh√≥ khƒÉn t√†i ch√≠nh ngay khi ch√∫ng ph√°t sinh.\n",
    "\n",
    "#### Credit Utilization\n",
    "\n",
    "T·ª∑ l·ªá s·ª≠ d·ª•ng h·∫°n m·ª©c t√≠n d·ª•ng l√† ch·ªâ s·ªë quan tr·ªçng ph·∫£n √°nh m·ª©c ƒë·ªô ph·ª• thu·ªôc c·ªßa doanh nghi·ªáp v√†o ngu·ªìn v·ªën vay ng√¢n h√†ng. Ch√∫ng ta t√≠nh to√°n hai ch·ªâ s·ªë ch√≠nh:\n",
    "\n",
    "**%util_mean_60d** l√† t·ª∑ l·ªá s·ª≠ d·ª•ng h·∫°n m·ª©c trung b√¨nh trong 60 ng√†y g·∫ßn nh·∫•t:\n",
    "\n",
    "$$\n",
    "\\text{Util Mean}_{60d} = \\frac{1}{60} \\sum_{t=1}^{60} \\frac{\\text{Utilized}_t}{\\text{Limit}_t}\n",
    "$$\n",
    "\n",
    "Ch·ªâ s·ªë n√†y cho bi·∫øt m·ª©c ƒë·ªô \"cƒÉng\" v·ªÅ thanh kho·∫£n c·ªßa doanh nghi·ªáp. Utilization rate v∆∞·ª£t qu√° 85% cho th·∫•y doanh nghi·ªáp ƒëang √°p s√°t h·∫°n m·ª©c, c√≥ nguy c∆° thi·∫øu thanh kho·∫£n n·∫øu c√≥ b·∫•t k·ª≥ c√∫ s·ªëc n√†o.\n",
    "\n",
    "**%util_p95_60d** l√† percentile th·ª© 95 c·ªßa utilization trong 60 ng√†y:\n",
    "\n",
    "$$\n",
    "\\text{Util P95}_{60d} = P_{95}\\left(\\frac{\\text{Utilized}_t}{\\text{Limit}_t}\\right)_{t=1}^{60}\n",
    "$$\n",
    "\n",
    "Ch·ªâ s·ªë n√†y quan tr·ªçng v√¨ n√≥ cho th·∫•y trong nh·ªØng ng√†y \"x·∫•u nh·∫•t\", doanh nghi·ªáp s·ª≠ d·ª•ng bao nhi√™u ph·∫ßn trƒÉm h·∫°n m·ª©c, gi√∫p ph√°t hi·ªán c√°c giai ƒëo·∫°n cƒÉng th·∫≥ng thanh kho·∫£n t·∫°m th·ªùi.\n",
    "\n",
    "#### Delinquency Patterns\n",
    "\n",
    "Days Past Due (DPD) l√† ch·ªâ s·ªë tr·ª±c ti·∫øp nh·∫•t v·ªÅ kh√≥ khƒÉn thanh to√°n. Ch√∫ng ta ph√¢n t√≠ch DPD theo nhi·ªÅu g√≥c ƒë·ªô:\n",
    "\n",
    "**dpd_max_180d** l√† s·ªë ng√†y qu√° h·∫°n t·ªëi ƒëa trong 180 ng√†y qua:\n",
    "\n",
    "$$\n",
    "\\text{DPD Max}_{180d} = \\max_{t=1}^{180} (\\text{DPD}_t)\n",
    "$$\n",
    "\n",
    "Theo chu·∫©n m·ª±c ng√†nh, DPD v∆∞·ª£t qu√° 30 ng√†y ƒë∆∞·ª£c coi l√† early warning signal, trong khi DPD v∆∞·ª£t 90 ng√†y l√† d·∫•u hi·ªáu r√µ r√†ng c·ªßa default risk theo ƒë·ªãnh nghƒ©a Basel.\n",
    "\n",
    "**dpd_trend_180d** ƒëo l∆∞·ªùng xu h∆∞·ªõng c·ªßa DPD theo th·ªùi gian b·∫±ng h·ªá s·ªë g√≥c c·ªßa h·ªìi quy tuy·∫øn t√≠nh:\n",
    "\n",
    "$$\n",
    "\\text{DPD Trend}_{180d} = \\beta_1 \\text{ where } \\text{DPD}_t = \\beta_0 + \\beta_1 \\cdot t + \\epsilon_t\n",
    "$$\n",
    "\n",
    "Slope d∆∞∆°ng ($\\beta_1 > 0$) cho th·∫•y DPD ƒëang c√≥ xu h∆∞·ªõng tƒÉng d·∫ßn (t√¨nh h√¨nh x·∫•u ƒëi), trong khi slope √¢m ($\\beta_1 < 0$) cho th·∫•y doanh nghi·ªáp ƒëang c·∫£i thi·ªán kh·∫£ nƒÉng thanh to√°n.\n",
    "\n",
    "**near_due_freq_7d** ƒëo l∆∞·ªùng t·∫ßn su·∫•t \"g·∫ßn qu√° h·∫°n\" trong 7 ng√†y g·∫ßn nh·∫•t:\n",
    "\n",
    "$$\n",
    "\\text{Near Due Freq}_{7d} = \\frac{1}{7} \\sum_{t=1}^{7} \\mathbb{1}(0 < \\text{DPD}_t < 30)\n",
    "$$\n",
    "\n",
    "Ch·ªâ s·ªë n√†y gi√∫p ph√°t hi·ªán c√°c kh√°ch h√†ng th∆∞·ªùng xuy√™n tr·ªÖ h·∫°n nh∆∞ng ch∆∞a ƒë·∫øn m·ª©c qu√° h·∫°n nghi√™m tr·ªçng, ƒë√¢y l√† early warning quan tr·ªçng.\n",
    "\n",
    "#### Credit Limit Breach\n",
    "\n",
    "**limit_breach_cnt_90d** ƒë·∫øm s·ªë l·∫ßn kh√°ch h√†ng v∆∞·ª£t qu√° h·∫°n m·ª©c t√≠n d·ª•ng trong 90 ng√†y g·∫ßn nh·∫•t:\n",
    "\n",
    "$$\n",
    "\\text{Limit Breach Count}_{90d} = \\sum_{t=1}^{90} \\mathbb{1}(\\text{Utilized}_t > \\text{Limit}_t)\n",
    "$$\n",
    "\n",
    "B·∫•t k·ª≥ l·∫ßn vi ph·∫°m n√†o (> 0) ƒë·ªÅu l√† d·∫•u hi·ªáu c·∫£nh b√°o nghi√™m tr·ªçng, cho th·∫•y doanh nghi·ªáp c√≥ nhu c·∫ßu v·ªën v∆∞·ª£t qu√° kh·∫£ nƒÉng ƒë∆∞·ª£c ph√™ duy·ªát, ho·∫∑c h·ªá th·ªëng ki·ªÉm so√°t n·ªôi b·ªô k√©m.\n",
    "\n",
    "---\n",
    "\n",
    "### C. Cashflow Features\n",
    "\n",
    "D√≤ng ti·ªÅn l√† \"huy·∫øt m·∫°ch\" c·ªßa doanh nghi·ªáp, quan tr·ªçng h∆°n c·∫£ l·ª£i nhu·∫≠n k·∫ø to√°n trong vi·ªác d·ª± ƒëo√°n kh·∫£ nƒÉng v·ª° n·ª£. Ch√∫ng ta ph√¢n t√≠ch d√≤ng ti·ªÅn v√†o/ra h√†ng ng√†y trong 180 ng√†y qua ƒë·ªÉ t·∫°o c√°c features:\n",
    "\n",
    "**inflow_mean_60d** v√† **outflow_mean_60d** l√† d√≤ng ti·ªÅn v√†o v√† ra trung b√¨nh trong 60 ng√†y g·∫ßn nh·∫•t:\n",
    "\n",
    "$$\n",
    "\\text{Inflow Mean}_{60d} = \\frac{1}{60} \\sum_{t=1}^{60} \\text{Inflow}_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Outflow Mean}_{60d} = \\frac{1}{60} \\sum_{t=1}^{60} \\text{Outflow}_t\n",
    "$$\n",
    "\n",
    "Hai ch·ªâ s·ªë n√†y ph·∫£n √°nh quy m√¥ v√† t√≠nh ·ªïn ƒë·ªãnh c·ªßa ho·∫°t ƒë·ªông kinh doanh. S·ª± ch√™nh l·ªách l·ªõn gi·ªØa inflow v√† outflow (burn rate cao) l√† d·∫•u hi·ªáu c·∫£nh b√°o.\n",
    "\n",
    "**inflow_drop_60d** ƒëo l∆∞·ªùng t·ª∑ l·ªá gi·∫£m c·ªßa d√≤ng ti·ªÅn v√†o trong 60 ng√†y g·∫ßn nh·∫•t so v·ªõi median 6 th√°ng:\n",
    "\n",
    "$$\n",
    "\\text{Inflow Drop}_{60d} = \\frac{\\text{Median}_{6m}(\\text{Inflow}) - \\text{Mean}_{60d}(\\text{Inflow})}{\\text{Median}_{6m}(\\text{Inflow})}\n",
    "$$\n",
    "\n",
    "Ch·ªâ s·ªë n√†y gi√∫p ph√°t hi·ªán s·ªõm s·ª•t gi·∫£m doanh thu, m·ªôt trong nh·ªØng nguy√™n nh√¢n ch√≠nh d·∫´n ƒë·∫øn v·ª° n·ª£. Inflow drop v∆∞·ª£t qu√° 20% cho th·∫•y d√≤ng ti·ªÅn ƒëang gi·∫£m m·∫°nh, c·∫ßn c√≥ h√†nh ƒë·ªông can thi·ªáp ngay l·∫≠p t·ª©c.\n",
    "\n",
    "---\n",
    "\n",
    "### D. Covenant Breach Flags\n",
    "\n",
    "Covenant (ƒëi·ªÅu kho·∫£n r√†ng bu·ªôc) l√† c√°c ng∆∞·ª°ng t√†i ch√≠nh m√† kh√°ch h√†ng ph·∫£i duy tr√¨ theo h·ª£p ƒë·ªìng t√≠n d·ª•ng. Vi ph·∫°m covenant l√† early warning signal c·ª±c k·ª≥ quan tr·ªçng, th∆∞·ªùng x·∫£y ra tr∆∞·ªõc khi default th·ª±c s·ª± di·ªÖn ra.\n",
    "\n",
    "Ch√∫ng ta theo d√µi ba lo·∫°i covenant ch√≠nh v·ªõi ƒëi·ªÅu ki·ªán trigger:\n",
    "\n",
    "$$\n",
    "\\text{breach\\_icr} = \\mathbb{1}(\\text{ICR}_{\\text{TTM}} < 1.5)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{breach\\_dscr} = \\mathbb{1}(\\text{DSCR}_{\\text{TTM}} < 1.2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{breach\\_leverage} = \\mathbb{1}\\left(\\frac{\\text{Total Debt}}{\\text{EBITDA}_{\\text{TTM}}} > 4.0\\right)\n",
    "$$\n",
    "\n",
    "M·ªói breach flag l√† bi·∫øn nh·ªã ph√¢n (0/1), cho bi·∫øt kh√°ch h√†ng c√≥ vi ph·∫°m covenant t∆∞∆°ng ·ª©ng hay kh√¥ng. Vi ph·∫°m b·∫•t k·ª≥ covenant n√†o ƒë·ªÅu trigger c√°c h√†nh ƒë·ªông nh∆∞ renegotiation, tightening ƒëi·ªÅu ki·ªán, ho·∫∑c tƒÉng gi√°m s√°t.\n",
    "\n",
    "---\n",
    "\n",
    "### E. Normalization (Sector-Size)\n",
    "\n",
    "M·ªôt trong nh·ªØng th√°ch th·ª©c l·ªõn nh·∫•t trong credit scoring l√† so s√°nh c√°c doanh nghi·ªáp kh√°c nhau v·ªÅ quy m√¥ v√† ng√†nh ngh·ªÅ. M·ªôt SME trong ng√†nh Retail c√≥ ICR = 2.0 c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† t·ªët, nh∆∞ng c√πng ch·ªâ s·ªë ƒë√≥ v·ªõi m·ªôt Large Corporate trong ng√†nh IT l·∫°i l√† m·ª©c trung b√¨nh ho·∫∑c k√©m.\n",
    "\n",
    "ƒê·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y, ch√∫ng ta √°p d·ª•ng **Z-score normalization** theo nh√≥m (Sector, Size_bucket). M·ªói feature ƒë∆∞·ª£c chu·∫©n h√≥a b·∫±ng c√°ch so s√°nh v·ªõi c√°c kh√°ch h√†ng c√πng ng√†nh v√† c√πng quy m√¥:\n",
    "\n",
    "$$\n",
    "Z\\text{-score} = \\frac{x - \\text{Median}_{\\text{group}}}{\\text{IQR}_{\\text{group}}}\n",
    "$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $x$ = gi√° tr·ªã feature c·ªßa kh√°ch h√†ng\n",
    "- $\\text{Median}_{\\text{group}}$ = trung v·ªã c·ªßa nh√≥m (Sector, Size_bucket)\n",
    "- $\\text{IQR}_{\\text{group}}$ = Interquartile Range (Q3 - Q1) c·ªßa nh√≥m\n",
    "\n",
    "Ch√∫ng ta s·ª≠ d·ª•ng **Median v√† IQR** thay v√¨ Mean v√† Standard Deviation v√¨ ch√∫ng robust h∆°n v·ªõi outliers, r·∫•t ph·ªï bi·∫øn trong d·ªØ li·ªáu t√†i ch√≠nh. Features sau khi normalize c√≥ suffix `__zs_sector_size`, v√≠ d·ª•: `icr_ttm__zs_sector_size`, `dpd_max_180d__zs_sector_size`.\n",
    "\n",
    "Normalization n√†y mang l·∫°i hai l·ª£i √≠ch quan tr·ªçng: (1) So s√°nh c√¥ng b·∫±ng gi·ªØa c√°c doanh nghi·ªáp c√πng ƒë·∫∑c ƒëi·ªÉm, v√† (2) TƒÉng s·ª©c m·∫°nh d·ª± ƒëo√°n c·ªßa model v√¨ features ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh theo context ri√™ng c·ªßa t·ª´ng nh√≥m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1876c",
   "metadata": {},
   "source": [
    "## Step 3: Model Training & Calibration\n",
    "\n",
    "Module: `src/train_baseline.py`\n",
    "\n",
    "### Overview\n",
    "\n",
    "B∆∞·ªõc n√†y x√¢y d·ª±ng m√¥ h√¨nh Machine Learning ƒë·ªÉ d·ª± ƒëo√°n x√°c su·∫•t v·ª° n·ª£ (PD) trong 12 th√°ng t·ªõi. Ch√∫ng ta s·ª≠ d·ª•ng **LightGBM** l√†m classifier c∆° s·ªü v√¨ kh·∫£ nƒÉng x·ª≠ l√Ω t·ªët nhi·ªÅu features, t·ª± ƒë·ªông h·ªçc ƒë∆∞·ª£c c√°c m·ªëi quan h·ªá phi tuy·∫øn, v√† h·ªó tr·ª£ class balancing. Sau khi train, m√¥ h√¨nh ƒë∆∞·ª£c **calibrate** b·∫±ng Isotonic Regression ƒë·ªÉ ƒë·∫£m b·∫£o predicted probabilities ph·∫£n √°nh ƒë√∫ng true probabilities - ƒëi·ªÅu quan tr·ªçng cho credit risk management v√† tu√¢n th·ªß Basel.\n",
    "\n",
    "---\n",
    "\n",
    "### A. LightGBM Configuration\n",
    "\n",
    "LightGBM ƒë∆∞·ª£c ch·ªçn v√¨ x·ª≠ l√Ω t·ªët nhi·ªÅu features c√≥ quy m√¥ kh√°c nhau (financial ratios, utilization rates, DPD counts), t·ª± ƒë·ªông h·ªçc feature interactions (\"ICR th·∫•p + Utilization cao = R·ªßi ro cao\"), v√† h·ªó tr·ª£ class weighting cho imbalanced data (default rate ~5-10%).\n",
    "\n",
    "**Hyperparameters:**\n",
    "\n",
    "```python\n",
    "LGBMClassifier(\n",
    "    n_estimators=300,           # 300 c√¢y trong ensemble\n",
    "    learning_rate=0.05,         # H·ªçc ch·∫≠m nh∆∞ng ·ªïn ƒë·ªãnh\n",
    "    num_leaves=15,              # Gi·ªõi h·∫°n complexity\n",
    "    max_depth=6,                # Tr√°nh overfitting\n",
    "    subsample=0.8,              # Row sampling (bagging)\n",
    "    colsample_bytree=0.8,       # Column sampling\n",
    "    min_child_samples=10,       # M·ªói leaf ‚â• 10 samples\n",
    "    reg_lambda=0.1,             # L2 regularization\n",
    "    scale_pos_weight=(1-pos_rate)/pos_rate,  # Auto-balance classes\n",
    "    objective='binary',\n",
    "    random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "**Train-Test Split**: 80% training, 20% holdout test v·ªõi stratified sampling ƒë·ªÉ ƒë·∫£m b·∫£o default rate ƒë·ªìng ƒë·ªÅu.\n",
    "\n",
    "---\n",
    "\n",
    "### B. Isotonic Calibration (CV=5)\n",
    "\n",
    "Gradient boosting models th∆∞·ªùng cho ra **uncalibrated probabilities** - khi model d·ª± ƒëo√°n PD = 20%, t·ª∑ l·ªá th·ª±c t·∫ø default c√≥ th·ªÉ l√† 15% ho·∫∑c 30%. Trong credit risk, ƒëi·ªÅu n√†y nguy hi·ªÉm v√¨ c√°c quy·∫øt ƒë·ªãnh quan tr·ªçng (capital allocation, pricing, provisioning) d·ª±a v√†o con s·ªë PD n√†y.\n",
    "\n",
    "**Isotonic Regression** l√† ph∆∞∆°ng ph√°p calibration non-parametric v√† monotonic, h·ªçc h√†m mapping t·ª´ raw probabilities sang calibrated probabilities v·ªõi r√†ng bu·ªôc ƒë∆°n ƒëi·ªáu tƒÉng (customer c√≥ raw PD cao h∆°n v·∫´n c√≥ calibrated PD cao h∆°n). Ch√∫ng ta s·ª≠ d·ª•ng 5-fold CV ƒë·ªÉ tr√°nh overfitting:\n",
    "\n",
    "```python\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "calibrated_model = CalibratedClassifierCV(\n",
    "    base_lgbm,\n",
    "    method='isotonic',\n",
    "    cv=5\n",
    ")\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Isotonic Regression ƒë∆∞·ª£c ∆∞u ti√™n h∆°n Platt Scaling v√¨: (1) Kh√¥ng gi·∫£ ƒë·ªãnh functional form (kh√¥ng c·∫ßn sigmoid), (2) ƒê·∫£m b·∫£o ranking kh√¥ng ƒë·ªïi, (3) Performance t·ªët h∆°n v·ªõi sample size l·ªõn (‚â• 1000 customers).\n",
    "\n",
    "---\n",
    "\n",
    "### C. Risk Tiers & Thresholds\n",
    "\n",
    "Sau calibration, customers ƒë∆∞·ª£c ph√¢n lo·∫°i v√†o 3 risk tiers d·ª±a tr√™n **percentile-based thresholds** (thay v√¨ absolute PD cutoffs) ƒë·ªÉ qu·∫£n l√Ω capacity. Ng√¢n h√†ng ch·ªâ c√≥ ƒë·ªß ngu·ªìn l·ª±c ƒë·ªÉ qu·∫£n l√Ω ch·∫∑t ch·∫Ω m·ªôt s·ªë l∆∞·ª£ng customers high-risk nh·∫•t, n√™n vi·ªác c·ªë ƒë·ªãnh Red tier = top 5% ƒë·∫£m b·∫£o s·ªë l∆∞·ª£ng customers c·∫ßn intensive monitoring kh√¥ng v∆∞·ª£t qu√° capacity.\n",
    "\n",
    "**Tier Definitions:**\n",
    "\n",
    "| Tier | Percentile | Typical PD | Action | Capacity |\n",
    "|------|-----------|-----------|--------|----------|\n",
    "| **Red** | Top 5% | ‚â• 20% | H·ªçp KH ‚â§5 ng√†y; l·∫≠p cash flow 13 tu·∫ßn; tighten covenants; watchlist | ~50 KH ‚Üí 5 RMs |\n",
    "| **Amber** | Top 5-15% | 5-20% | So√°t x√©t ‚â§10 ng√†y; y√™u c·∫ßu management accounts; h·∫°n ch·∫ø h·∫°n m·ª©c | ~100 KH ‚Üí 10 RMs |\n",
    "| **Green** | Bottom 85% | < 5% | Theo d√µi ƒë·ªãnh k·ª≥ quarterly; kh√¥ng c·∫ßn h√†nh ƒë·ªông ƒë·∫∑c bi·ªát | Portfolio monitoring |\n",
    "\n",
    "**Threshold Calculation:**\n",
    "\n",
    "```python\n",
    "train_probs = calibrated_model.predict_proba(X_train)[:, 1]\n",
    "red_threshold = np.percentile(train_probs, 95)      # e.g., 0.23\n",
    "amber_threshold = np.percentile(train_probs, 85)    # e.g., 0.08\n",
    "```\n",
    "\n",
    "Thresholds ƒë∆∞·ª£c l∆∞u v√†o `thresholds.json` v√† s·ª≠ d·ª•ng nh·∫•t qu√°n cho c√°c l·∫ßn scoring sau.\n",
    "\n",
    "---\n",
    "\n",
    "### D. Evaluation Metrics\n",
    "\n",
    "Model ƒë∆∞·ª£c ƒë√°nh gi√° to√†n di·ªán qua nhi·ªÅu metrics, m·ªói metric ƒëo l∆∞·ªùng m·ªôt kh√≠a c·∫°nh kh√°c nhau:\n",
    "\n",
    "**1. AUC-ROC (Discrimination Power)**  \n",
    "ƒêo kh·∫£ nƒÉng ph√¢n bi·ªát defaulters vs non-defaulters. AUC = 0.80 nghƒ©a l√† 80% tr∆∞·ªùng h·ª£p model s·∫Ω rank ƒë√∫ng (assign PD cao h∆°n cho defaulter). **Target**: ‚â• 0.75 (industry standard).\n",
    "\n",
    "**2. PR-AUC (Precision-Recall)**  \n",
    "Quan tr·ªçng v·ªõi imbalanced data (default rate th·∫•p). Precision = % customers ƒë∆∞·ª£c d·ª± ƒëo√°n default th·ª±c s·ª± default. Recall = % defaults th·ª±c t·∫ø ƒë∆∞·ª£c ph√°t hi·ªán. **Target**: ‚â• 0.40 (v·ªõi base rate ~8%).\n",
    "\n",
    "**3. KS Statistic (Kolmogorov-Smirnov)**  \n",
    "ƒêo maximum separation gi·ªØa cumulative distributions c·ªßa defaulters v√† non-defaulters. KS = max(TPR - FPR). **Target**: ‚â• 0.35 (good discriminatory power).\n",
    "\n",
    "**4. Brier Score (Calibration Quality)**  \n",
    "MSE c·ªßa probabilities: `Brier = (1/N) √ó Œ£(predicted_prob - actual_outcome)¬≤`. Brier nh·ªè nghƒ©a l√† predictions accurate (n·∫øu d·ª± ƒëo√°n 10 KH m·ªói ng∆∞·ªùi PD=20%, l√Ω t∆∞·ªüng c√≥ 2 defaults). **Target**: ‚â§ 0.10. Brier gi·∫£m ƒë√°ng k·ªÉ sau calibration (t·ª´ ~0.12 xu·ªëng ~0.08).\n",
    "\n",
    "**5. Calibration Curve (Reliability Diagram)**  \n",
    "Visualize calibration: plot mean predicted probability vs actual default rate trong t·ª´ng bin. ƒê∆∞·ªùng l√Ω t∆∞·ªüng l√† y = x (diagonal).\n",
    "\n",
    "---\n",
    "\n",
    "### E. Outputs & Artifacts\n",
    "\n",
    "**1. Model File**: `model_lgbm.pkl` - Ch·ª©a base LightGBM, calibrated model, feature names, v√† metadata (training date, hyperparameters, test AUC, test Brier).\n",
    "\n",
    "**2. Scores**: `scores_all.csv` - Predictions cho to√†n b·ªô dataset (train + test) v·ªõi columns: `customer_id`, `prob_default_12m_base`, `prob_default_12m_calibrated`, `tier`, `is_test`.\n",
    "\n",
    "**3. Thresholds**: `thresholds.json` - L∆∞u red/amber/green thresholds v√† percentiles ƒë·ªÉ d√πng cho scoring sau n√†y.\n",
    "\n",
    "**4. Visualizations**:\n",
    "- `calibration_lgbm.png`: Reliability diagram (before vs after calibration)\n",
    "- `pr_curve_lgbm.png`: Precision-Recall curve\n",
    "- `roc_curve_lgbm.png`: ROC curve  \n",
    "- `shap_summary.png`: Quick SHAP summary (top 10 features)\n",
    "\n",
    "T·∫•t c·∫£ artifacts ƒë∆∞·ª£c version control ƒë·ªÉ ƒë·∫£m b·∫£o reproducibility v√† auditability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69772d3",
   "metadata": {},
   "source": [
    "## Step 3.5: Model Monitoring\n",
    "\n",
    "Module: `run_monitoring.py`\n",
    "\n",
    "### V·∫•n ƒë·ªÅ Model Degradation\n",
    "\n",
    "Sau khi train, model c√≥ AUC = 0.93 tr√™n test set. Nh∆∞ng trong production, performance c√≥ th·ªÉ gi·∫£m d·∫ßn theo th·ªùi gian do 3 nguy√™n nh√¢n:\n",
    "\n",
    "**1. Data Drift**: Portfolio thay ƒë·ªïi (v√≠ d·ª•: ng√¢n h√†ng chuy·ªÉn t·ª´ cho vay Manufacturing sang Tech). Features c√≥ distribution kh√°c so v·ªõi training data ‚Üí model predictions kh√¥ng c√≤n reliable.\n",
    "\n",
    "**2. Concept Drift**: Quan h·ªá gi·ªØa features v√† default risk thay ƒë·ªïi (v√≠ d·ª•: ICR < 1.5 t·ª´ng l√† strong signal, nh∆∞ng sau government support programs, nhi·ªÅu firms c√≥ low ICR v·∫´n kh√¥ng default). Model h·ªçc patterns c≈©, kh√¥ng c√≤n √°p d·ª•ng ƒë∆∞·ª£c.\n",
    "\n",
    "**3. Calibration Drift**: Predicted probabilities kh√¥ng c√≤n ch√≠nh x√°c. Model d·ª± ƒëo√°n 100 customers c√≥ PD = 20% m·ªói ng∆∞·ªùi, nh∆∞ng th·ª±c t·∫ø ch·ªâ 10 ng∆∞·ªùi default (10%) thay v√¨ 20 ng∆∞·ªùi (20%). Brier Score tƒÉng cao.\n",
    "\n",
    "‚Üí **Monitoring l√† b·∫Øt bu·ªôc** ƒë·ªÉ ph√°t hi·ªán nh·ªØng thay ƒë·ªïi n√†y tr∆∞·ªõc khi ·∫£nh h∆∞·ªüng business decisions.\n",
    "\n",
    "---\n",
    "\n",
    "### Metrics Monitoring\n",
    "\n",
    "**PSI (Population Stability Index)**: ƒêo distribution shift c·ªßa features.\n",
    "\n",
    "$$\n",
    "\\text{PSI} = \\sum_{i=1}^{n} (\\text{Actual}_i - \\text{Expected}_i) \\times \\ln\\left(\\frac{\\text{Actual}_i}{\\text{Expected}_i}\\right)\n",
    "$$\n",
    "\n",
    "Chia m·ªói feature th√†nh bins (quantiles), t√≠nh % observations trong m·ªói bin cho baseline vs current data. PSI cao nghƒ©a l√† distribution thay ƒë·ªïi nhi·ªÅu.\n",
    "\n",
    "- **PSI < 0.10**: Distribution ·ªïn ƒë·ªãnh, model v·∫´n ho·∫°t ƒë·ªông t·ªët\n",
    "- **0.10 ‚â§ PSI < 0.25**: C√≥ shift nh·∫π, c·∫ßn investigate xem features n√†o thay ƒë·ªïi v√† t·∫°i sao\n",
    "- **PSI ‚â• 0.25**: Severe shift, model kh√¥ng c√≤n ph√π h·ª£p v·ªõi data hi·ªán t·∫°i ‚Üí **Ph·∫£i retrain**\n",
    "\n",
    "---\n",
    "\n",
    "**Performance Metrics**: So s√°nh AUC, PR-AUC, KS, Brier gi·ªØa baseline v√† current data.\n",
    "\n",
    "| Metric | Baseline | Current | Degradation Threshold |\n",
    "|--------|----------|---------|----------------------|\n",
    "| **AUC** | 0.9309 | 0.9315 | < 0.70 ho·∫∑c gi·∫£m > 5% |\n",
    "| **PR-AUC** | 0.1782 | 0.1789 | Gi·∫£m > 10% |\n",
    "| **KS** | 0.7927 | 0.7901 | Gi·∫£m > 20% |\n",
    "| **Brier** | 0.0194 | 0.0195 | > 0.15 ho·∫∑c tƒÉng > 5% |\n",
    "\n",
    "**AUC < 0.70**: Model m·∫•t kh·∫£ nƒÉng ph√¢n bi·ªát defaulters vs non-defaulters ‚Üí Worse than random ranking.\n",
    "\n",
    "**Brier > 0.15**: Calibration ho√†n to√†n sai, predictions kh√¥ng ƒë√°ng tin c·∫≠y cho decision making.\n",
    "\n",
    "**KS gi·∫£m 20%**: Separation gi·ªØa good v√† bad customers gi·∫£m m·∫°nh, tiers (Red/Amber/Green) kh√¥ng c√≤n meaningful.\n",
    "\n",
    "---\n",
    "\n",
    "### Workflow T·ª± ƒë·ªông\n",
    "\n",
    "`run_monitoring.py` ƒë∆∞·ª£c t√≠ch h·ª£p s·∫µn v·ªõi `train_baseline.py`:\n",
    "\n",
    "1. **Training** t·ª± ƒë·ªông t·∫°o `baseline_metrics.json` (AUC, Brier tr√™n test set) v√† `feature_ews_train.parquet` (training data)\n",
    "2. **Monitoring** load baseline metrics, predict tr√™n current data, t√≠nh PSI + performance metrics\n",
    "3. **Alerting** t·ª± ƒë·ªông c·∫£nh b√°o n·∫øu v∆∞·ª£t thresholds (AUC < 0.70, PSI ‚â• 0.25, Brier > 0.15)\n",
    "4. **Logging** l∆∞u k·∫øt qu·∫£ v√†o `monitoring_YYYYMMDD_HHMMSS.json` v√† `psi_details.csv` ƒë·ªÉ track trends\n",
    "\n",
    "‚Üí Production team ch·∫°y monitoring **h√†ng th√°ng** v·ªõi data th√°ng m·ªõi. N·∫øu c√≥ alerts, tri·ªáu t·∫≠p Data Science team ƒë·ªÉ retrain ho·∫∑c recalibrate model.\n",
    "\n",
    "---\n",
    "\n",
    "### Khi n√†o Retrain?\n",
    "\n",
    "**Nguy√™n t·∫Øc**: Retrain khi model kh√¥ng c√≤n reflect current reality.\n",
    "\n",
    "- **AUC < 0.70**: Discrimination power qu√° th·∫•p\n",
    "- **PSI ‚â• 0.25**: Portfolio ƒë√£ thay ƒë·ªïi qu√° nhi·ªÅu so v·ªõi training period\n",
    "- **Brier > 0.15**: Probabilities kh√¥ng c√≤n ch√≠nh x√°c cho capital allocation/provisioning\n",
    "\n",
    "**Best practice**: Retrain **quarterly** v·ªõi 2-3 nƒÉm data g·∫ßn nh·∫•t ƒë·ªÉ model lu√¥n capture latest patterns, ngay c·∫£ khi metrics ch∆∞a degradation nghi√™m tr·ªçng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a18bb",
   "metadata": {},
   "source": [
    "## Step 4: Model Explainability (SHAP)\n",
    "\n",
    "Module: `src/explain.py`\n",
    "\n",
    "### Overview\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) gi·∫£i th√≠ch contribution c·ªßa t·ª´ng feature v√†o prediction d·ª±a tr√™n game theory. SHAP value d∆∞∆°ng nghƒ©a l√† feature ƒë√≥ tƒÉng x√°c su·∫•t default, √¢m nghƒ©a l√† gi·∫£m default risk, v√† magnitude cho bi·∫øt m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng. ƒêi·ªÅu n√†y quan tr·ªçng cho Credit Committee (gi·∫£i th√≠ch decisions), RM Team (t∆∞ v·∫•n customers c·∫£i thi·ªán), v√† Model Validation (ƒë·∫£m b·∫£o model h·ªçc ƒë√∫ng patterns).\n",
    "\n",
    "---\n",
    "\n",
    "### Global Explainability\n",
    "\n",
    "**Feature Importance** (`feature_importance.csv`): Mean absolute SHAP values cho m·ªói feature, cho bi·∫øt features n√†o ·∫£nh h∆∞·ªüng nh·∫•t ƒë·∫øn model trong to√†n b·ªô portfolio. V√≠ d·ª•, `dpd_max_180d__zs_sector_size` th∆∞·ªùng l√† feature quan tr·ªçng nh·∫•t v√¨ DPD l√† signal m·∫°nh nh·∫•t cho default risk.\n",
    "\n",
    "**SHAP Summary Plot** (`shap_summary.png`): Waterfall plot visualize impact c·ªßa t·∫•t c·∫£ features. M·ªói ƒëi·ªÉm l√† m·ªôt customer, m√†u ƒë·ªè = feature value cao, xanh = feature value th·∫•p. Plot n√†y cho th·∫•y kh√¥ng ch·ªâ feature n√†o quan tr·ªçng m√† c√≤n direction c·ªßa impact (high DPD ‚Üí high risk, high ICR ‚Üí low risk).\n",
    "\n",
    "---\n",
    "\n",
    "### Local Explainability\n",
    "\n",
    "**Top Drivers per Customer** (`top_drivers_per_customer.csv`): Top 5 features quan tr·ªçng nh·∫•t cho t·ª´ng customer c·ª• th·ªÉ, gi√∫p tr·∫£ l·ªùi c√¢u h·ªèi \"T·∫°i sao customer C0042 ƒë∆∞·ª£c ph√¢n v√†o Red tier?\". Output bao g·ªìm feature name, SHAP value, v√† actual feature value.\n",
    "\n",
    "V√≠ d·ª• cho customer C0042:\n",
    "1. `dpd_max_180d__zs_sector_size`: SHAP = +0.52 (value = 120 days) ‚Üí DPD cao\n",
    "2. `%util_mean_60d__zs_sector_size`: SHAP = +0.31 (value = 0.95) ‚Üí Utilization s√°t h·∫°n m·ª©c\n",
    "3. `icr_ttm__zs_sector_size`: SHAP = +0.20 (value = 0.8) ‚Üí ICR th·∫•p, kh√≥ tr·∫£ l√£i\n",
    "\n",
    "V·ªõi th√¥ng tin n√†y, RM c√≥ th·ªÉ t∆∞ v·∫•n customer: (1) Clear outstanding payments ƒë·ªÉ gi·∫£m DPD, (2) Gi·∫£m credit usage ho·∫∑c apply for limit increase, (3) C·∫£i thi·ªán profitability ho·∫∑c restructure debt.\n",
    "\n",
    "---\n",
    "\n",
    "### Dependence Plots\n",
    "\n",
    "SHAP dependence plots cho key features (`icr_ttm`, `ccc`, `%util_mean_60d`) hi·ªÉn th·ªã m·ªëi quan h·ªá phi tuy·∫øn gi·ªØa feature value v√† SHAP value. V√≠ d·ª•, dependence plot c·ªßa ICR c√≥ th·ªÉ cho th·∫•y: ICR < 1.5 c√≥ SHAP values r·∫•t cao (risk tƒÉng m·∫°nh), ICR 1.5-3.0 c√≥ SHAP gi·∫£m d·∫ßn, ICR > 3.0 c√≥ SHAP g·∫ßn 0 (kh√¥ng c√≤n r·ªßi ro th√™m). Nh·ªØng insights n√†y gi√∫p validate model ƒëang h·ªçc ƒë√∫ng business logic.\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs Summary\n",
    "\n",
    "| File | Type | Purpose |\n",
    "|------|------|---------|\n",
    "| `feature_importance.csv` | Global | Ranking features by importance |\n",
    "| `shap_summary.png` | Global | Visual impact of all features |\n",
    "| `top_drivers_per_customer.csv` | Local | Top 5 drivers cho t·ª´ng customer |\n",
    "| `shap_dependence_*.png` | Global | Phi tuy·∫øn relationships |\n",
    "| `summary.json` | Metadata | Config v√† stats |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121d40f",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 5-6: [Optional] Re-calibration\n",
    "\n",
    "### Why Optional?\n",
    "\n",
    "B∆∞·ªõc 3 (train_baseline.py) ƒë√£ t·∫°o ra m·ªôt **calibrated model** v·ªõi percentile-based thresholds (Red = top 5%, Amber = top 5-15%) s·∫µn s√†ng cho production. Steps 5-6 ch·ªâ c·∫ßn thi·∫øt khi business mu·ªën **thay ƒë·ªïi threshold strategy** t·ª´ percentile-based sang **absolute PD cutoffs** (v√≠ d·ª•: Red ‚â• 20% PD, Amber ‚â• 5% PD) ƒë·ªÉ ph√π h·ª£p v·ªõi risk appetite ho·∫∑c regulatory requirements c·ª• th·ªÉ.\n",
    "\n",
    "Trong th·ª±c t·∫ø, percentile-based approach th∆∞·ªùng ƒë∆∞·ª£c ∆∞u ti√™n v√¨ ƒë·∫£m b·∫£o s·ªë l∆∞·ª£ng customers c·∫ßn intensive monitoring kh√¥ng v∆∞·ª£t qu√° capacity. Tuy nhi√™n, m·ªôt s·ªë t·ªï ch·ª©c (ƒë·∫∑c bi·ªát banks tu√¢n th·ªß Basel/IFRS 9) y√™u c·∫ßu absolute thresholds ƒë·ªÉ nh·∫•t qu√°n v·ªõi internal risk rating systems ho·∫∑c regulatory reporting.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Extract Raw Scores\n",
    "\n",
    "**Module**: `src/make_scores_raw.py`\n",
    "\n",
    "Tr√≠ch xu·∫•t raw probabilities t·ª´ **base LightGBM** (tr∆∞·ªõc khi √°p d·ª•ng isotonic calibration trong Step 3) ƒë·ªÉ c√≥ baseline scores cho re-calibration process. Output l√† `scores_raw.csv` ch·ª©a uncalibrated predictions cho to√†n b·ªô dataset.\n",
    "\n",
    "**Why needed?** Re-calibration c·∫ßn raw scores l√†m input v√¨ ch√∫ng ta s·∫Ω fit m·ªôt calibrator m·ªõi v·ªõi absolute thresholds kh√°c v·ªõi calibrator trong Step 3.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 6: Re-calibrate with Absolute Thresholds\n",
    "\n",
    "**Module**: `src/calibrate.py`\n",
    "\n",
    "Fit l·∫°i **Isotonic Regression** tr√™n raw scores v·ªõi absolute PD cutoffs thay v√¨ percentiles. Process bao g·ªìm: (1) Fit calibrator tr√™n training set, (2) Map raw scores ‚Üí calibrated PD, (3) Apply absolute thresholds (Red ‚â• 20%, Amber ‚â• 5%), (4) Save calibrator v√† thresholds.\n",
    "\n",
    "**Key difference from Step 3:**\n",
    "- Step 3: Calibrate ‚Üí Calculate percentile thresholds ‚Üí Tiers fixed by % (top 5%, 10%)\n",
    "- Step 6: Calibrate ‚Üí Apply absolute PD thresholds ‚Üí Tiers vary by portfolio quality\n",
    "\n",
    "**Outputs:**\n",
    "- `calibrator.pkl`: New isotonic calibrator\n",
    "- `mapping.csv`: Raw score ‚Üí Calibrated PD mapping table\n",
    "- `thresholds.json`: Absolute cutoffs (red: 0.20, amber: 0.05)\n",
    "- `calibration_full.png`: Reliability diagram\n",
    "- `pr_curve_full.png`: Precision-Recall curve\n",
    "\n",
    "**Tradeoff:** V·ªõi absolute thresholds, s·ªë l∆∞·ª£ng customers trong Red/Amber tiers c√≥ th·ªÉ bi·∫øn ƒë·ªông theo quality c·ªßa portfolio (good period ‚Üí √≠t Red, bad period ‚Üí nhi·ªÅu Red), g√¢y kh√≥ khƒÉn cho capacity planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3385969",
   "metadata": {},
   "source": [
    "## üéØ Step 7: Production Scoring\n",
    "\n",
    "Module: `src/scoring.py`\n",
    "\n",
    "Scoring l√† b∆∞·ªõc cu·ªëi c√πng ƒë·ªÉ ƒë∆∞a model v√†o production. Script n√†y load trained model, predict PD cho to√†n b·ªô customers d·ª±a tr√™n feature snapshot t·∫°i as-of date (v√≠ d·ª•: 2025-06-30), sau ƒë√≥ ph√¢n tier v√† ƒë∆∞a ra action recommendations. Output ƒë∆∞·ª£c s·ª≠ d·ª•ng tr·ª±c ti·∫øp b·ªüi RM team v√† Risk Committee ƒë·ªÉ ra quy·∫øt ƒë·ªãnh nghi·ªáp v·ª•.\n",
    "\n",
    "---\n",
    "\n",
    "### Inputs & Outputs\n",
    "\n",
    "**Inputs:**\n",
    "1. **Features**: `data/processed/feature_ews.parquet` - Feature snapshot t·∫°i as-of date\n",
    "2. **Model**: `artifacts/models/model_lgbm.pkl` - Trained & calibrated LightGBM\n",
    "3. **Thresholds**: `artifacts/calibration/thresholds.json` ho·∫∑c `artifacts/models/thresholds.json` - T√πy approach (absolute vs percentile)\n",
    "\n",
    "**Output**: `ews_scored_YYYY-MM-DD.csv` v·ªõi columns:\n",
    "\n",
    "| Column | Description | Example |\n",
    "|--------|-------------|---------|\n",
    "| `customer_id` | Customer identifier | C0042 |\n",
    "| `prob_default_12m_calibrated` | PD trong 12 th√°ng (0-1) | 0.2341 |\n",
    "| `score_ews` | EWS Score (0-100) | 76.59 |\n",
    "| `tier` | Risk tier | Red |\n",
    "| `action` | Recommended action | H·ªçp KH ‚â§5 ng√†y; l·∫≠p cash flow 13 tu·∫ßn;... |\n",
    "\n",
    "**EWS Score Formula**: `100 √ó (1 - PD)` ‚Üí Score cao = R·ªßi ro th·∫•p (100 = t·ªët nh·∫•t, 0 = x·∫•u nh·∫•t)\n",
    "\n",
    "---\n",
    "\n",
    "### Risk Tiers & Actions\n",
    "\n",
    "| Tier | Criteria | Action | Frequency |\n",
    "|------|----------|--------|-----------|\n",
    "| **Green** | PD < 5% (ho·∫∑c bottom 85%) | Theo d√µi ƒë·ªãnh k·ª≥; c·∫≠p nh·∫≠t BCTC ƒë√∫ng h·∫°n | Quarterly |\n",
    "| **Amber** | 5% ‚â§ PD < 20% (ho·∫∑c top 5-15%) | So√°t x√©t RM ‚â§10 ng√†y; y√™u c·∫ßu management accounts; ki·ªÉm tra c√¥ng n·ª£; h·∫°n ch·∫ø h·∫°n m·ª©c | Monthly |\n",
    "| **Red** | PD ‚â• 20% (ho·∫∑c top 5%) | H·ªçp KH ‚â§5 ng√†y; l·∫≠p cash flow 13 tu·∫ßn; xem x√©t covenant tightening/collateral; watchlist | Weekly |\n",
    "\n",
    "**Note**: Criteria ph·ª• thu·ªôc v√†o threshold approach (absolute vs percentile) ƒë∆∞·ª£c ch·ªçn ·ªü Steps 3 ho·∫∑c 5-6.\n",
    "\n",
    "---\n",
    "\n",
    "### Production Workflow\n",
    "\n",
    "**Monthly Cadence**:\n",
    "1. **Last day of month**: Ch·∫°y scoring script v·ªõi as-of date = month-end\n",
    "2. **Day 1-2**: Ph√¢n ph·ªëi report cho RM team v√† Risk Committee\n",
    "3. **Day 3-10**: RMs th·ª±c hi·ªán actions theo tier (Amber reviews, Red meetings)\n",
    "4. **Throughout month**: Track action completion v√† update customer status\n",
    "\n",
    "**Integration v·ªõi Banking Systems**:\n",
    "- **Input**: Features t·ª´ core banking system (financial data, credit transactions, cashflow)\n",
    "- **Output**: EWS scores import v√†o CRM/Credit Risk systems\n",
    "- **Alerts**: Auto-trigger emails/notifications cho customers chuy·ªÉn sang Red tier\n",
    "\n",
    "**Monitoring**: Track tier migrations month-over-month ƒë·ªÉ identify portfolio trends (improving/deteriorating)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6774e35",
   "metadata": {},
   "source": [
    "## üìä Model Performance & Validation\n",
    "\n",
    "### Expected Performance Metrics (Holdout 20%)\n",
    "\n",
    "Model ƒë∆∞·ª£c ƒë√°nh gi√° tr√™n holdout test set v·ªõi c√°c metrics sau (computed trong `train_baseline.py` lines 99-104):\n",
    "\n",
    "| Metric | Target Range | √ù nghƒ©a | Code |\n",
    "|--------|-------------|---------|------|\n",
    "| **AUC-ROC** | 0.75 - 0.85 | Kh·∫£ nƒÉng ph√¢n bi·ªát defaulters vs non-defaulters | `roc_auc_score(y_te, p_te)` |\n",
    "| **PR-AUC** | 0.40 - 0.60 | Performance tr√™n positive class (quan tr·ªçng v·ªõi imbalanced data) | `average_precision_score(y_te, p_te)` |\n",
    "| **KS Statistic** | 0.35 - 0.50 | Maximum separation gi·ªØa cumulative distributions | `ks_score(y_te, p_te)` |\n",
    "| **Brier Score** | 0.05 - 0.10 | Calibration quality (lower is better) | `brier_score_loss(y_te, p_te)` |\n",
    "\n",
    "**Calibration Quality**: Reliability curve (predicted probabilities vs actual default rates) n√™n g·∫ßn diagonal (y = x). Isotonic calibration c·∫£i thi·ªán ƒë√°ng k·ªÉ metric n√†y, th∆∞·ªùng gi·∫£m Brier score t·ª´ ~0.12 xu·ªëng ~0.08. Plots ƒë∆∞·ª£c generate trong `plot_calibration_pr()` function (lines 47-61).\n",
    "\n",
    "**Precision-Recall Tradeoff**: Red threshold (PD ‚â• 20%) c√≥ high precision, moderate recall; Amber threshold (PD ‚â• 5%) c√≥ balanced precision-recall.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Monitoring & Maintenance\n",
    "\n",
    "**Quarterly Reviews** (c·∫ßn t·ª± implement monitoring scripts):\n",
    "1. **Performance drift**: Monitor AUC, KS tr√™n new data (target: kh√¥ng gi·∫£m > 5%)\n",
    "   - Re-run `train_baseline.py` tr√™n new data v√† compare metrics\n",
    "2. **Population Stability Index (PSI)**: ƒêo distribution shift c·ªßa features (target: PSI < 0.15)\n",
    "   - Formula: `PSI = Œ£(actual% - expected%) √ó ln(actual%/expected%)`\n",
    "3. **Feature stability**: Check data quality, missing values, outliers\n",
    "   - S·ª≠ d·ª•ng data profiling tools ho·∫∑c pandas `.describe()`\n",
    "4. **Recalibration**: N·∫øu Brier score tƒÉng > 0.10, consider re-fit calibrator\n",
    "   - Re-run Step 6 (`calibrate.py`) v·ªõi data m·ªõi\n",
    "\n",
    "**Red Flags Trigger Retraining**:\n",
    "- AUC drops below 0.70\n",
    "- Brier score > 0.15\n",
    "- Large prediction shifts without business explanation (e.g., 10% customers chuy·ªÉn tier b·∫•t th∆∞·ªùng)\n",
    "- PSI > 0.25 (severe distribution shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe319a76",
   "metadata": {},
   "source": [
    "## Feature Importance Ranking\n",
    "\n",
    "D·ª±a tr√™n SHAP analysis trong `explain.py`, ƒë√¢y l√† 10 features c√≥ impact m·∫°nh nh·∫•t ƒë·∫øn d·ª± b√°o default:\n",
    "\n",
    "| # | Feature Name | Category | Business Interpretation |\n",
    "|---|--------------|----------|------------------------|\n",
    "| 1 | `dpd_max_180d__zs_sector_size` | Behavioral | DPD t·ªëi ƒëa trong 6 th√°ng - signal m·∫°nh nh·∫•t cho default risk |\n",
    "| 2 | `%util_mean_60d__zs_sector_size` | Behavioral | Credit utilization trung b√¨nh - ph·∫£n √°nh liquidity stress |\n",
    "| 3 | `icr_ttm__zs_sector_size` | Financial | Interest Coverage Ratio - kh·∫£ nƒÉng tr·∫£ l√£i vay |\n",
    "| 4 | `debt_to_ebitda__zs_sector_size` | Financial | Financial leverage - m·ª©c ƒë·ªô ƒë√≤n b·∫©y t√†i ch√≠nh |\n",
    "| 5 | `ccc__zs_sector_size` | Financial | Cash Conversion Cycle - hi·ªáu qu·∫£ qu·∫£n l√Ω v·ªën l∆∞u ƒë·ªông |\n",
    "| 6 | `inflow_drop_60d__zs_sector_size` | Cashflow | M·ª©c gi·∫£m doanh thu - suy gi·∫£m cashflow |\n",
    "| 7 | `dpd_trend_180d__zs_sector_size` | Behavioral | Xu h∆∞·ªõng DPD tƒÉng - payment behavior ƒëang x·∫•u ƒëi |\n",
    "| 8 | `breach_icr` | Covenant | Vi ph·∫°m covenant ICR - trigger event tr·ª±c ti·∫øp |\n",
    "| 9 | `current_ratio__zs_sector_size` | Financial | Current Ratio < 1.0 - nguy c∆° thanh kho·∫£n ng·∫Øn h·∫°n |\n",
    "| 10 | `delta_ccc_qoq__zs_sector_size` | Financial | Thay ƒë·ªïi CCC theo qu√Ω - efficiency ƒëang gi·∫£m |\n",
    "\n",
    "### Ph√¢n t√≠ch theo Category\n",
    "\n",
    "- **Behavioral (40%)**: Payment patterns th·ª±c t·∫ø l√† predictor m·∫°nh nh·∫•t - DPD history v√† utilization cho signal s·ªõm nh·∫•t v·ªÅ kh√≥ khƒÉn t√†i ch√≠nh\n",
    "- **Financial (35%)**: C√°c ch·ªâ s·ªë t√†i ch√≠nh fundamental (ICR, leverage, liquidity ratios) quan tr·ªçng th·ª© hai\n",
    "- **Cashflow (15%)**: Revenue trends v√† cashflow dynamics detect deterioration s·ªõm h∆°n b√°o c√°o t√†i ch√≠nh\n",
    "- **Covenant (10%)**: Breach events c√≥ impact ƒë√°ng k·ªÉ nh∆∞ng xu·∫•t hi·ªán mu·ªôn h∆°n\n",
    "\n",
    "**K·∫øt lu·∫≠n**: Model ∆∞u ti√™n behavioral signals v√¨ payment difficulties xu·∫•t hi·ªán tr∆∞·ªõc khi financial statements ph·∫£n √°nh ƒë·∫ßy ƒë·ªß. ƒêi·ªÅu n√†y ph√π h·ª£p v·ªõi th·ª±c t·∫ø risk management trong credit monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4792cd",
   "metadata": {},
   "source": [
    "## üöÄ Complete End-to-End Pipeline\n",
    "\n",
    "### Full Workflow (Development)\n",
    "\n",
    "```bash\n",
    "# Step 1: Generate synthetic data\n",
    "python src/generate_data.py --n-customers 1000 --output-dir data/raw\n",
    "\n",
    "# Step 2: Feature engineering\n",
    "python src/feature_engineering.py --raw-dir data/raw --asof 2025-06-30 --outdir data/processed\n",
    "\n",
    "# Step 3: Train model + calibration\n",
    "python src/train_baseline.py --features data/processed/feature_ews.parquet --test-size 0.2 --seed 42 --red-pct 0.05 --amber-pct 0.10 --outdir artifacts/models\n",
    "\n",
    "# Step 4: Generate SHAP explanations\n",
    "python src/explain.py --model artifacts/models/model_lgbm.pkl --features data/processed/feature_ews.parquet --outdir artifacts/shap --max-display 20\n",
    "\n",
    "# [Optional] Step 5-6: Re-calibration with absolute thresholds\n",
    "python src/make_scores_raw.py --features data/processed/feature_ews.parquet --model artifacts/models/model_lgbm.pkl --out data/processed/scores_raw.csv\n",
    "python src/calibrate.py --input data/processed/scores_raw.csv --red-thr 0.20 --amber-thr 0.05 --outdir artifacts/calibration\n",
    "\n",
    "# Step 7: Production scoring\n",
    "python src/scoring.py --features data/processed/feature_ews.parquet --model artifacts/models/model_lgbm.pkl --thresholds artifacts/calibration/thresholds.json --asof 2025-06-30 --outdir artifacts/scoring\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1732f",
   "metadata": {},
   "source": [
    "## üìà Artifacts & Outputs Summary\n",
    "\n",
    "### Directory Structure\n",
    "\n",
    "```\n",
    "artifacts/\n",
    "‚îú‚îÄ‚îÄ models/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ model_lgbm.pkl              # Trained model (base + calibrated + features)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ scores_all.csv              # Training set predictions + tiers\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ thresholds.json             # Percentile-based thresholds\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ calibration_lgbm.png        # Reliability diagram\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ pr_curve_lgbm.png           # Precision-Recall curve\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ shap_summary.csv/png        # Quick SHAP summary\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ calibration/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ calibrator.pkl              # Isotonic calibrator (re-fitted)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ mapping.csv                 # Raw score ‚Üí Calibrated PD mapping\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ thresholds.json             # Absolute PD thresholds (Red ‚â•20%, Amber ‚â•5%)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ calibration_full.png        # Reliability curve (re-calibrated)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ pr_curve_full.png           # PR curve (re-calibrated)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ shap/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.csv      # Global feature importance (mean |SHAP|)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ shap_summary.png            # SHAP waterfall plot\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ top_drivers_per_customer.csv # Local explanations (top 5 features per customer)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ shap_dependence_*.png       # Dependence plots for key features\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ summary.json                # Metadata\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ scoring/\n",
    "    ‚îú‚îÄ‚îÄ ews_scored_2025-06-30.csv   # Production scores (customer_id, PD, score, tier, action)\n",
    "    ‚îî‚îÄ‚îÄ thresholds_used.json        # Thresholds applied in this run\n",
    "```\n",
    "\n",
    "### Key Files for Different Stakeholders\n",
    "\n",
    "| Stakeholder | Key Files |\n",
    "|-------------|-----------|\n",
    "| **Risk Manager** | `ews_scored_*.csv`, `top_drivers_per_customer.csv` |\n",
    "| **Credit Committee** | `scores_all.csv`, `shap_summary.png`, `pr_curve_lgbm.png` |\n",
    "| **Data Scientist** | `model_lgbm.pkl`, `feature_importance.csv`, all plots |\n",
    "| **Model Validator** | `calibration_*.png`, `thresholds.json`, metrics in console output |\n",
    "| **Auditor** | All artifacts + `summary.json` for traceability |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b992b",
   "metadata": {},
   "source": [
    "## üî¨ Technical Deep Dives\n",
    "\n",
    "### 1. Why Isotonic Calibration?\n",
    "\n",
    "**Problem with raw LightGBM probabilities:**\n",
    "- Overconfident near 0 and 1\n",
    "- Not well-calibrated for credit risk (regulatory requirement)\n",
    "\n",
    "**Isotonic Regression:**\n",
    "- Non-parametric, monotonic calibration\n",
    "- Preserves ranking (AUC unchanged)\n",
    "- Improves Brier score and reliability\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Class Imbalance Handling\n",
    "\n",
    "**Default rate ~5-10%** ‚Üí Highly imbalanced\n",
    "\n",
    "**Strategies applied:**\n",
    "1. **`scale_pos_weight`** in LightGBM\n",
    "   - Automatically weights positive class\n",
    "   - Formula: `(n_negative / n_positive)`\n",
    "   \n",
    "2. **Evaluation metrics:** PR-AUC instead of just ROC-AUC\n",
    "   - ROC-AUC can be misleading with imbalanced data\n",
    "   \n",
    "3. **Threshold tuning:** Separate from 0.5\n",
    "   - Red/Amber thresholds based on business capacity\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Feature Normalization (Sector-Size)\n",
    "\n",
    "**Why normalize by (Sector, Size)?**\n",
    "\n",
    "```python\n",
    "# Example: ICR = 2.0 for a SME in Retail\n",
    "# Is this good or bad?\n",
    "\n",
    "# Without normalization: Compare to all companies ‚Üí Looks average\n",
    "# With sector-size normalization: Compare to SME Retailers ‚Üí Looks good!\n",
    "\n",
    "# Implementation:\n",
    "def sector_size_normalize(df, cols):\n",
    "    for c in cols:\n",
    "        grouped = df.groupby(['sector_code', 'size_bucket'])\n",
    "        median = grouped[c].transform('median')\n",
    "        iqr = grouped[c].transform(lambda x: x.quantile(0.75) - x.quantile(0.25))\n",
    "        df[f'{c}__zs_sector_size'] = (df[c] - median) / iqr\n",
    "    return df\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Fair comparison (SME vs SME, Corp vs Corp, same sector)\n",
    "- Robust to outliers (median/IQR instead of mean/std)\n",
    "- Better predictive power\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Label Definition: Event Horizon = 12 Months\n",
    "\n",
    "**Basel Standard:** PD typically measured over 12-month horizon\n",
    "\n",
    "**Label rule:**\n",
    "```python\n",
    "# Default if: DPD ‚â• 90 days for at least 30 consecutive days in next 12M\n",
    "dpd_90_plus_days = sum(dpd >= 90 for dpd in future_dpd_sequence)\n",
    "event_h12m = 1 if dpd_90_plus_days >= 30 else 0\n",
    "```\n",
    "\n",
    "**Rationale:**\n",
    "- 90 DPD: Industry standard for \"default\"\n",
    "- 30 consecutive days: Avoid transient spikes\n",
    "- 12M horizon: Align with regulatory reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aecc20",
   "metadata": {},
   "source": [
    "## üéì Basel & Regulatory Alignment\n",
    "\n",
    "### Basel Framework Compliance\n",
    "\n",
    "**1. PD (Probability of Default) Estimation**\n",
    "- ‚úÖ 12-month horizon (Basel standard)\n",
    "- ‚úÖ Through-the-cycle (TTC) calibration via Isotonic Regression\n",
    "- ‚úÖ Backtesting with holdout set\n",
    "\n",
    "**2. Key Financial Ratios**\n",
    "- ‚úÖ **ICR (Interest Coverage Ratio):** EBIT / Interest\n",
    "- ‚úÖ **DSCR (Debt Service Coverage Ratio):** (EBITDA - CAPEX) / Debt Service\n",
    "- ‚úÖ **Leverage Ratio:** Total Debt / EBITDA\n",
    "- ‚úÖ **Liquidity Ratio:** Current Assets / Current Liabilities\n",
    "\n",
    "**3. Early Warning Indicators**\n",
    "- ‚úÖ DPD tracking (30, 60, 90+ days)\n",
    "- ‚úÖ Credit limit breach monitoring\n",
    "- ‚úÖ Covenant breach flags\n",
    "- ‚úÖ Cashflow deterioration signals\n",
    "\n",
    "**4. Model Governance**\n",
    "- ‚úÖ **Explainability:** SHAP for transparency\n",
    "- ‚úÖ **Calibration:** Reliability curves\n",
    "- ‚úÖ **Validation:** AUC, KS, Brier on holdout\n",
    "- ‚úÖ **Documentation:** All artifacts saved with metadata\n",
    "\n",
    "---\n",
    "\n",
    "### Risk Appetite Framework\n",
    "\n",
    "**Tier Definitions aligned with Risk Appetite:**\n",
    "\n",
    "| Tier | PD Range | Portfolio Allocation | Risk Appetite |\n",
    "|------|----------|---------------------|---------------|\n",
    "| Green | < 5% | 85% | Accept: Standard monitoring |\n",
    "| Amber | 5-20% | 10% | Tolerate: Enhanced monitoring |\n",
    "| Red | ‚â• 20% | 5% | Mitigate/Exit: Immediate action |\n",
    "\n",
    "**Capacity Management:**\n",
    "- Red tier (5%): Max ~50 customers ‚Üí 5 FTE RM (10 customers/RM)\n",
    "- Amber tier (10%): Max ~100 customers ‚Üí 10 FTE RM (10 customers/RM)\n",
    "- Green tier (85%): Portfolio monitoring only\n",
    "\n",
    "---\n",
    "\n",
    "### Regulatory Reporting\n",
    "\n",
    "**Outputs compatible with:**\n",
    "- **IFRS 9:** Expected Credit Loss (ECL) calculation\n",
    "  - PD √ó LGD √ó EAD = ECL\n",
    "  - Model provides PD component\n",
    "  \n",
    "- **Basel II/III:** Internal Ratings-Based (IRB) approach\n",
    "  - PD model for corporate exposures\n",
    "  - Complement with LGD and EAD models\n",
    "  \n",
    "- **Stress Testing:** Scenario-based PD adjustments\n",
    "  - Re-run model with stressed features\n",
    "  - Example: Revenue shock, Interest rate shock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055acd37",
   "metadata": {},
   "source": [
    "## References & Resources\n",
    "\n",
    "### Academic & Industry Papers\n",
    "\n",
    "1. **Basel Committee on Banking Supervision**\n",
    "   - [Basel II: International Convergence of Capital Measurement](https://www.bis.org/publ/bcbs128.htm)\n",
    "   - PD, LGD, EAD estimation frameworks\n",
    "   \n",
    "2. **IFRS 9 - Expected Credit Loss**\n",
    "   - 12-month vs Lifetime PD\n",
    "   - Staging models (Stage 1, 2, 3)\n",
    "\n",
    "3. **Altman Z-Score (1968)**\n",
    "   - Classic credit scoring model for manufacturing firms\n",
    "   - Foundation for many modern models\n",
    "\n",
    "4. **SHAP: Lundberg & Lee (2017)**\n",
    "   - [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)\n",
    "   - Game-theoretic feature attribution\n",
    "\n",
    "---\n",
    "\n",
    "### Tools & Libraries\n",
    "\n",
    "**Python Packages:**\n",
    "- `lightgbm`: Gradient boosting framework\n",
    "- `shap`: Model explainability\n",
    "- `scikit-learn`: ML utilities, calibration\n",
    "- `pandas`, `numpy`: Data manipulation\n",
    "- `matplotlib`, `seaborn`, `plotly`: Visualization\n",
    "\n",
    "**Development:**\n",
    "- `ruff`: Fast Python linter & formatter\n",
    "- `pytest`: Testing framework\n",
    "- `cookiecutter-data-science`: Project template\n",
    "\n",
    "---\n",
    "\n",
    "### Contact & Support\n",
    "\n",
    "**Project Maintainer:** Duong N.C.K  \n",
    "**Repository:** [github.com/dylanng3/corporate-credit-ews](https://github.com/dylanng3/corporate-credit-ews)  \n",
    "**License:** MIT License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
