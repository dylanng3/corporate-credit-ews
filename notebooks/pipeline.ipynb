{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86858a9",
   "metadata": {},
   "source": [
    "# Corporate Credit Early Warning System (EWS)\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Hệ thống cảnh báo sớm rủi ro tín dụng doanh nghiệp (Corporate Credit EWS) được xây dựng theo chuẩn Basel, sử dụng Machine Learning để dự đoán xác suất vỡ nợ (PD - Probability of Default) trong vòng 12 tháng tới.\n",
    "\n",
    "**Mục tiêu chính:**\n",
    "- Dự đoán khả năng vỡ nợ của khách hàng doanh nghiệp (event horizon: 12 tháng)\n",
    "- Phân loại rủi ro thành 3 tiers: **Green** (an toàn), **Amber** (cảnh báo), **Red** (nguy hiểm)\n",
    "- Đưa ra khuyến nghị hành động cụ thể cho Risk Management team\n",
    "\n",
    "**Tech Stack:**\n",
    "- Python 3.13\n",
    "- LightGBM (classification model)\n",
    "- SHAP (model explainability)\n",
    "- Sklearn (calibration, metrics)\n",
    "- Pandas/Numpy (data processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f0cf4",
   "metadata": {},
   "source": [
    "## Pipeline Architecture\n",
    "\n",
    "Dự án được tổ chức theo **end-to-end ML pipeline** với 7 bước chính:\n",
    "\n",
    "```\n",
    "1. Data Generation (generate_data.py)\n",
    "   ↓\n",
    "2. Feature Engineering (feature_engineering.py)\n",
    "   ↓\n",
    "3. Model Training + Calibration (train_baseline.py)\n",
    "   ↓\n",
    "4. Model Explainability (explain.py)\n",
    "   ↓\n",
    "5. [Optional] Make Raw Scores (make_scores_raw.py)\n",
    "   ↓\n",
    "6. [Optional] Re-calibration (calibrate.py)\n",
    "   ↓\n",
    "7. Production Scoring (scoring.py)\n",
    "```\n",
    "\n",
    "### Data Flow\n",
    "- **Raw Data** → `data/raw/` (fin_quarterly, credit_daily, cashflow_daily, covenant, labels)\n",
    "- **Features** → `data/processed/` (feature_ews.parquet)\n",
    "- **Models** → `artifacts/models/` (model_lgbm.pkl, SHAP artifacts)\n",
    "- **Scores** → `artifacts/scoring/` (ews_scored_YYYY-MM-DD.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fd11a",
   "metadata": {},
   "source": [
    "## Step 1: Data Generation\n",
    "\n",
    "Module: `src/generate_data.py`\n",
    "\n",
    "### Overview\n",
    "\n",
    "Tạo dữ liệu synthetic (giả lập) để train và test model EWS. Dữ liệu được thiết kế sát với thực tế nghiệp vụ tín dụng doanh nghiệp và tuân thủ các nguyên tắc Basel.\n",
    "\n",
    "### Why Synthetic Data?\n",
    "\n",
    "#### Lợi ích và hạn chế\n",
    "Lợi ích của việc sử dụng dữ liệu tổng hợp là tránh được vấn đề bảo mật và rủi ro tuân thủ do sử dụng các dữ liệu nội bộ từ ngân hàng. Bên cạnh đó, ta có thể biết chính xác ground truth dữ liệu đầu vào của mô hình (ở đây là event_12m), điều mà vô cùng quan trọng khi xây dựng các thuật toán học máy như LightGBM. Ngoài ra, chúng ta giải quyết được vấn đề scaling bằng việc dễ dàng tạo 1K, 10K, 100K dữ liệu khách hàng, điều mà khá khó khăn với những dự án có kinh phí thấp và khả năng tiếp cận hạn chế đối với dữ liệu thật. Một lợi thế khác khi sử dụng dữ liệu tổng hợp là khả năng thực hiện các edge cases và stress scenarios: những trường hợp dữ liệu nằm ở biên của phân phối thông thường, rất ít khi xuất hiện trong dữ liệu thực tế.\n",
    "\n",
    "Hạn chế lớn nhất của việc sử dụng dữ liệu tổng hợp là sự khác biệt về phân phối (distribution shift) so với dữ liệu thực tế. Nếu dữ liệu tổng hợp không mô phỏng chính xác mối quan hệ phức tạp và các sắc thái ẩn trong dữ liệu gốc của ngân hàng, mô hình được huấn luyện trên đó có thể hoạt động kém hiệu quả hoặc đưa ra các dự đoán sai lệch nghiêm trọng khi áp dụng vào môi trường thực tế. \n",
    "\n",
    "#### Vai trò\n",
    "Dữ liệu tổng hợp có vai trò thiết yếu trong nhiều giai đoạn của dự án khoa học dữ liệu. Nó được sử dụng để chứng minh tính khả thi (Proof-of-concept) của mô hình hoặc giải pháp trước khi áp dụng lên dữ liệu thật, giúp giảm thiểu rủi ro. Ngoài ra, dữ liệu này là công cụ lý tưởng để huấn luyện các đội ngũ mới mà không cần tiếp xúc với thông tin nhạy cảm.\n",
    "\n",
    "---\n",
    "\n",
    "### Customer Profile Configuration\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Config:\n",
    "    n_customers: int = 1000\n",
    "    sectors: Tuple[str, ...] = (\n",
    "        \"MFG\",  # Manufacturing (18%)\n",
    "        \"TRA\",  # Trading (12%)\n",
    "        \"CON\",  # Construction (10%)\n",
    "        \"AGR\",  # Agriculture (8%)\n",
    "        \"ENG\",  # Engineering (8%)\n",
    "        \"CHE\",  # Chemicals (10%)\n",
    "        \"RET\",  # Retail (12%)\n",
    "        \"LOG\",  # Logistics (10%)\n",
    "        \"TEL\",  # Telecom (6%)\n",
    "        \"IT\"    # Information Technology (6%)\n",
    "    )\n",
    "    size_buckets: Tuple[str, ...] = (\"SME\", \"Corp\")\n",
    "    size_probs: Tuple[float, ...] = (0.8, 0.2)  # 80% SME, 20% Corp\n",
    "```\n",
    "\n",
    "**Sector Risk Premiums:**\n",
    "Mỗi sector có risk premium khác nhau (thêm vào debt_mult):\n",
    "- **Low risk:** ENG (0.0), MFG (0.0), TEL (-0.01), IT (-0.02)\n",
    "- **Medium risk:** CHE (0.02), LOG (0.02), RET (0.03), CON (0.03)\n",
    "- **Higher risk:** AGR (0.04), TRA (0.05)\n",
    "\n",
    "**Size Characteristics:**\n",
    "- **SME (Small-Medium Enterprise):**\n",
    "  - Base revenue: lognormal(mean=10.5, σ=0.5)\n",
    "  - Debt multiplier: 0.8 + 0.4 = 1.2\n",
    "  - Higher default risk due to less stability\n",
    "  \n",
    "- **Corp (Large Corporate):**\n",
    "  - Base revenue: lognormal(mean=12, σ=0.5)  → ~2.7x larger\n",
    "  - Debt multiplier: 0.8 + 0.6 = 1.4\n",
    "  - More stable but higher leverage\n",
    "\n",
    "---\n",
    "\n",
    "### Data Tables Generated\n",
    "\n",
    "#### 1. **fin_quarterly.parquet** - Báo cáo tài chính theo quý\n",
    "\n",
    "**Time Range:** 12 quarters (3 years) history ending at `2025-06-30`\n",
    "\n",
    "**Columns (15 total):**\n",
    "\n",
    "| Column | Description | Generation Logic |\n",
    "|--------|-------------|------------------|\n",
    "| `customer_id` | Unique ID (C0001-C1000) | Sequential |\n",
    "| `fq_date` | Quarter end date | 2022-09-30 → 2025-06-30 |\n",
    "| `sector_code` | Industry sector | Random từ 10 sectors |\n",
    "| `size_bucket` | SME or Corp | 80/20 split |\n",
    "| `revenue` | Quarterly revenue | Growth ~2% QoQ + noise |\n",
    "| `cogs` | Cost of Goods Sold | ~75% of revenue |\n",
    "| `ebitda` | Earnings Before Interest, Tax, D&A | ~15% margin + noise |\n",
    "| `ebit` | Earnings Before Interest & Tax | EBITDA - D&A (proxy 2% revenue) |\n",
    "| `interest_expense` | Quarterly interest | Debt × 8% annual / 4 |\n",
    "| `total_debt` | Total outstanding debt | Revenue × (0.3 + sector_risk) × debt_mult |\n",
    "| `current_assets` | AR + Inventory + Cash | Function of revenue/COGS |\n",
    "| `current_liab` | AP + short-term liabilities | Function of COGS/revenue |\n",
    "| `inventory` | Inventory level | ~12% of COGS |\n",
    "| `ar` | Accounts Receivable | ~18% of revenue (DSO ~66 days) |\n",
    "| `ap` | Accounts Payable | ~20% of COGS (DPO ~73 days) |\n",
    "\n",
    "**Realism Features:**\n",
    "- ✅ **Growth patterns:** QoQ growth ~2% ± 5% noise\n",
    "- ✅ **Profitability:** EBITDA margin 15% ± 7%\n",
    "- ✅ **Leverage:** Debt/Revenue varies by sector\n",
    "- ✅ **Working capital:** Realistic DSO, DPO, Inventory turnover\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **credit_daily.parquet** - Hành vi tín dụng hàng ngày\n",
    "\n",
    "**Time Range:** \n",
    "- Observation window: 180 days before `asof_date` (2025-01-02 → 2025-06-30)\n",
    "- Label window: 365 days after `asof_date` (2025-07-01 → 2026-06-30)\n",
    "- **Total:** 545 days per customer\n",
    "\n",
    "**Columns (7 total):**\n",
    "\n",
    "| Column | Description | Generation Logic |\n",
    "|--------|-------------|------------------|\n",
    "| `customer_id` | Customer ID | - |\n",
    "| `date` | Business date | Daily from start to end |\n",
    "| `limit` | Credit limit | 30% of latest revenue × randomness |\n",
    "| `utilized` | Amount used | Limit × utilization_rate |\n",
    "| `breach_flag` | 1 if utilized > limit | Binary indicator |\n",
    "| `dpd_days` | Days Past Due | Markov chain: 98.5% stay/improve, 1.5% deteriorate |\n",
    "| `product_type` | OD/TERM/TR_LOAN | 70% Overdraft, 20% Term Loan, 10% Trade Finance |\n",
    "\n",
    "**DPD Markov Process:**\n",
    "```python\n",
    "# Each day:\n",
    "if random() < 0.985:\n",
    "    dpd = max(0, dpd - binomial(1, p=0.3))  # 30% chance giảm 1 ngày\n",
    "else:\n",
    "    dpd += choice([1, 3, 7], p=[0.6, 0.3, 0.1])  # 60% +1, 30% +3, 10% +7\n",
    "```\n",
    "\n",
    "**Utilization Pattern:**\n",
    "```python\n",
    "util_level = beta(2, 2)  # Centered around 0.5\n",
    "seasonal = sin(day_of_year/365 * 2π) * 0.05  # ±5% seasonality\n",
    "daily_util = util_level + seasonal + noise(0, 0.05)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **cashflow_daily.parquet** - Dòng tiền hàng ngày\n",
    "\n",
    "**Time Range:** Same as credit_daily (545 days)\n",
    "\n",
    "**Columns (4 total):**\n",
    "\n",
    "| Column | Description | Generation Logic |\n",
    "|--------|-------------|------------------|\n",
    "| `customer_id` | Customer ID | - |\n",
    "| `date` | Business date | Daily |\n",
    "| `inflow` | Cash inflow | Daily avg revenue × seasonality × noise |\n",
    "| `outflow` | Cash outflow | ~90% of inflow × noise |\n",
    "\n",
    "**Seasonality Model:**\n",
    "```python\n",
    "daily_mean = annual_revenue / 365 × uniform(0.6, 1.1)\n",
    "seasonal_factor = 1 + 0.2 × sin(day_of_year/365 × 2π)\n",
    "inflow = max(0, normal(daily_mean × seasonal_factor, σ=daily_mean×0.3))\n",
    "outflow = max(0, normal(inflow × 0.9, σ=daily_mean×0.25))\n",
    "```\n",
    "\n",
    "**Use cases:**\n",
    "- Detect sudden revenue drops (inflow_drop_60d)\n",
    "- Monitor burn rate (outflow > inflow)\n",
    "- Identify cashflow volatility\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **covenant.parquet** - Covenant tracking\n",
    "\n",
    "**Time Range:** Daily for observation + label windows\n",
    "\n",
    "**Columns (7 total):**\n",
    "\n",
    "| Column | Description | Threshold | Breach Logic |\n",
    "|--------|-------------|-----------|--------------|\n",
    "| `customer_id` | Customer ID | - | - |\n",
    "| `date` | Business date | - | - |\n",
    "| `icr` | Interest Coverage | ≥ 1.5 | 1 if < 1.5 |\n",
    "| `dscr` | Debt Service Coverage | ≥ 1.2 | 1 if < 1.2 |\n",
    "| `leverage` | Debt/EBITDA | ≤ 4.0 | 1 if > 4.0 |\n",
    "| `breach_icr` | ICR breach flag | - | Binary |\n",
    "| `breach_dscr` | DSCR breach flag | - | Binary |\n",
    "| `breach_leverage` | Leverage breach flag | - | Binary |\n",
    "\n",
    "**Why Important:**\n",
    "- Covenant breach = Early warning signal\n",
    "- Typical in loan agreements\n",
    "- Triggers renegotiation or penalties\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **labels.parquet** - Target variable\n",
    "\n",
    "**Columns (3 total):**\n",
    "\n",
    "| Column | Description | Logic |\n",
    "|--------|-------------|-------|\n",
    "| `customer_id` | Customer ID | - |\n",
    "| `asof_date` | Snapshot date | 2025-06-30 |\n",
    "| `event_h12m` | Default in 12M | 1 if DPD ≥ 90 for ≥ 30 consecutive days |\n",
    "\n",
    "**Label Definition (Basel-compliant):**\n",
    "```python\n",
    "def compute_label(future_dpd_series):\n",
    "    \"\"\"\n",
    "    future_dpd_series: DPD values for 365 days after asof_date\n",
    "    \"\"\"\n",
    "    max_consecutive_90plus = 0\n",
    "    current_streak = 0\n",
    "    \n",
    "    for dpd in future_dpd_series:\n",
    "        if dpd >= 90:\n",
    "            current_streak += 1\n",
    "            max_consecutive_90plus = max(max_consecutive_90plus, current_streak)\n",
    "        else:\n",
    "            current_streak = 0\n",
    "    \n",
    "    return 1 if max_consecutive_90plus >= 30 else 0\n",
    "```\n",
    "\n",
    "**Additional Bumps (increase default probability):**\n",
    "- **High utilization bump:** If util_rate > 90% at asof_date → +20% PD\n",
    "- **Covenant breach bump:** If any covenant breached → +20% PD\n",
    "\n",
    "**Expected Default Rate:** ~5-10% (typical for corporate portfolio)\n",
    "\n",
    "---\n",
    "\n",
    "### Output Files\n",
    "\n",
    "All tables saved in both **Parquet** (preferred) and **CSV** (fallback):\n",
    "\n",
    "```\n",
    "data/raw/\n",
    "├── fin_quarterly.parquet       # ~1000 rows × 12 quarters = 12K rows\n",
    "├── credit_daily.parquet        # ~1000 customers × 545 days = 545K rows\n",
    "├── cashflow_daily.parquet      # ~1000 customers × 545 days = 545K rows\n",
    "├── covenant.parquet            # ~1000 customers × 545 days = 545K rows\n",
    "└── labels.parquet              # 1000 rows (one per customer)\n",
    "```\n",
    "\n",
    "**File sizes:**\n",
    "- Parquet: ~5-10 MB total (compressed)\n",
    "- CSV: ~30-50 MB total (uncompressed)\n",
    "\n",
    "---\n",
    "\n",
    "### Usage Example\n",
    "\n",
    "```bash\n",
    "# Generate with default config (1000 customers)\n",
    "python src/generate_data.py --output-dir data/raw\n",
    "\n",
    "# Generate 5000 customers for stress test\n",
    "python src/generate_data.py --n-customers 5000 --output-dir data/raw_large\n",
    "\n",
    "# Custom end date\n",
    "python src/generate_data.py --end-quarter 2024-12-31 --output-dir data/raw_2024\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Quality Checks\n",
    "\n",
    "**After generation, verify:**\n",
    "\n",
    "✅ **Completeness:** All 5 files generated  \n",
    "✅ **Row counts:** Consistent customer_ids across tables  \n",
    "✅ **Date ranges:** Correct observation (180d) + label (365d) windows  \n",
    "✅ **Label distribution:** Default rate 5-10%  \n",
    "✅ **Financial sanity:** Revenue > 0, EBITDA margin reasonable, Debt > 0  \n",
    "✅ **DPD distribution:** Majority < 30, some 30-90, few > 90  \n",
    "\n",
    "```python\n",
    "# Quick checks\n",
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_parquet('data/raw/labels.parquet')\n",
    "print(f\"Default rate: {labels['event_h12m'].mean():.1%}\")  # Should be ~5-10%\n",
    "\n",
    "credit = pd.read_parquet('data/raw/credit_daily.parquet')\n",
    "print(f\"Max DPD: {credit['dpd_days'].max()}\")  # Should see some 90+ days\n",
    "print(f\"Breach rate: {credit['breach_flag'].mean():.1%}\")  # Should be low ~1-5%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac84d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate synthetic data và verify kết quả\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1: GENERATE SYNTHETIC DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Command để generate data\n",
    "print(\"\\n📝 Command to generate data:\")\n",
    "print(\"python src/generate_data.py --n-customers 1000 --output-dir data/raw\")\n",
    "\n",
    "print(\"\\n📊 Expected outputs:\")\n",
    "outputs = {\n",
    "    \"fin_quarterly.parquet\": \"~12,000 rows (1000 customers × 12 quarters)\",\n",
    "    \"credit_daily.parquet\": \"~545,000 rows (1000 customers × 545 days)\",\n",
    "    \"cashflow_daily.parquet\": \"~545,000 rows (1000 customers × 545 days)\",\n",
    "    \"covenant.parquet\": \"~545,000 rows (1000 customers × 545 days)\",\n",
    "    \"labels.parquet\": \"1,000 rows (1 row per customer)\"\n",
    "}\n",
    "\n",
    "for file, desc in outputs.items():\n",
    "    print(f\"  ✓ data/raw/{file:30s} → {desc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFICATION AFTER GENERATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Nếu data đã tồn tại, verify nó\n",
    "data_dir = \"../data/raw\"\n",
    "if os.path.exists(data_dir):\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        \n",
    "        print(\"\\n✅ Data directory found! Checking files...\")\n",
    "        \n",
    "        # Check labels\n",
    "        labels_path = f\"{data_dir}/labels.parquet\"\n",
    "        if os.path.exists(labels_path):\n",
    "            labels = pd.read_parquet(labels_path)\n",
    "            default_rate = labels['event_h12m'].mean()\n",
    "            print(f\"\\n📌 labels.parquet:\")\n",
    "            print(f\"   - Total customers: {len(labels):,}\")\n",
    "            print(f\"   - Default rate (event_h12m=1): {default_rate:.1%}\")\n",
    "            print(f\"   - Expected: 5-10% ✓\" if 0.05 <= default_rate <= 0.15 else \"   - Warning: Outside expected range\")\n",
    "        \n",
    "        # Check credit_daily\n",
    "        credit_path = f\"{data_dir}/credit_daily.parquet\"\n",
    "        if os.path.exists(credit_path):\n",
    "            credit = pd.read_parquet(credit_path)\n",
    "            print(f\"\\n📌 credit_daily.parquet:\")\n",
    "            print(f\"   - Total rows: {len(credit):,}\")\n",
    "            print(f\"   - Date range: {credit['date'].min()} to {credit['date'].max()}\")\n",
    "            print(f\"   - Max DPD: {credit['dpd_days'].max()} days\")\n",
    "            print(f\"   - Breach rate: {credit['breach_flag'].mean():.1%}\")\n",
    "            print(f\"   - Avg utilization: {(credit['utilized']/credit['limit']).mean():.1%}\")\n",
    "        \n",
    "        # Check fin_quarterly\n",
    "        fin_path = f\"{data_dir}/fin_quarterly.parquet\"\n",
    "        if os.path.exists(fin_path):\n",
    "            fin = pd.read_parquet(fin_path)\n",
    "            print(f\"\\n📌 fin_quarterly.parquet:\")\n",
    "            print(f\"   - Total rows: {len(fin):,}\")\n",
    "            print(f\"   - Unique customers: {fin['customer_id'].nunique():,}\")\n",
    "            print(f\"   - Quarters: {fin['fq_date'].nunique()}\")\n",
    "            print(f\"   - Avg EBITDA margin: {(fin['ebitda']/fin['revenue']).mean():.1%}\")\n",
    "            print(f\"   - Avg Debt/EBITDA: {(fin['total_debt']/fin['ebitda']).mean():.1f}x\")\n",
    "        \n",
    "        print(\"\\n✅ All checks passed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️  Could not verify data: {e}\")\n",
    "        print(\"   Run the generate_data.py script first to create the data.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Data directory not found: {data_dir}\")\n",
    "    print(\"   Run the following command to generate data:\")\n",
    "    print(\"   python src/generate_data.py --n-customers 1000 --output-dir data/raw\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c495f97",
   "metadata": {},
   "source": [
    "## 🔧 Step 2: Feature Engineering\n",
    "\n",
    "Module: `src/feature_engineering.py`\n",
    "\n",
    "### Overview\n",
    "\n",
    "Feature Engineering là bước quan trọng nhất trong việc xây dựng mô hình Early Warning System, vì nó chuyển đổi dữ liệu thô từ các bảng tài chính, hành vi tín dụng, và dòng tiền thành các đặc trưng (features) có sức mạnh dự đoán cao. Quá trình này kết hợp kiến thức chuyên môn về tín dụng ngân hàng với kỹ thuật phân tích dữ liệu, tạo ra tập hợp các chỉ số phản ánh đầy đủ tình hình tài chính và rủi ro của khách hàng doanh nghiệp.\n",
    "\n",
    "Các features được thiết kế dựa trên các nguyên tắc Basel và thực tiễn quản lý rủi ro tín dụng, chia thành 5 nhóm chính: Financial Ratios, Behavioral Features, Cashflow Features, Covenant Breach Flags, và Normalization. Mỗi nhóm phục vụ một mục đích cụ thể trong việc đánh giá khả năng vỡ nợ của khách hàng.\n",
    "\n",
    "---\n",
    "\n",
    "### A. Financial Ratios (TTM - Trailing 12 Months)\n",
    "\n",
    "Các tỷ số tài chính được tính toán dựa trên dữ liệu 12 tháng gần nhất (TTM) để phản ánh xu hướng dài hạn và giảm thiểu ảnh hưởng của biến động ngắn hạn. Chúng ta sử dụng dữ liệu từ 4 quý gần nhất để tính toán các chỉ số tổng hợp này.\n",
    "\n",
    "#### Liquidity & Coverage Ratios\n",
    "\n",
    "**Interest Coverage Ratio (ICR)** là chỉ số quan trọng nhất trong đánh giá khả năng trả nợ, được tính bằng EBIT chia cho chi phí lãi vay (Interest Expense). Tỷ số này đo lường khả năng của doanh nghiệp trong việc trả lãi vay từ lợi nhuận hoạt động. Theo thông lệ ngành ngân hàng, ICR dưới 1.5 được coi là mức nguy hiểm, cho thấy doanh nghiệp không đủ khả năng trang trải nghĩa vụ lãi vay từ thu nhập hoạt động.\n",
    "\n",
    "**Debt Service Coverage Ratio (DSCR)** đo lường khả năng trả cả nợ gốc và lãi từ EBITDA sau khi trừ đi chi phí vốn (CAPEX). Do dữ liệu synthetic không có thông tin chi tiết về khoản trả nợ gốc, chúng ta sử dụng proxy bằng cách ước tính CAPEX là 30% của EBITDA. DSCR dưới 1.2 cho thấy doanh nghiệp gặp khó khăn trong việc đáp ứng các nghĩa vụ nợ.\n",
    "\n",
    "**Current Ratio** phản ánh thanh khoản ngắn hạn, được tính bằng tài sản ngắn hạn (Current Assets) chia cho nợ ngắn hạn (Current Liabilities). Tỷ số này cho biết khả năng của doanh nghiệp trong việc thanh toán các khoản nợ đến hạn trong vòng 12 tháng tới. Current Ratio dưới 1.0 là dấu hiệu cảnh báo thiếu thanh khoản nghiêm trọng.\n",
    "\n",
    "#### Leverage Ratio\n",
    "\n",
    "**Debt-to-EBITDA** đo lường đòn bẩy tài chính, cho biết doanh nghiệp cần bao nhiêu năm EBITDA để trả hết nợ. Tỷ số này được tính bằng tổng nợ (Total Debt) chia cho EBITDA TTM. Theo chuẩn mực ngành, Debt-to-EBITDA vượt quá 4.0 cho thấy doanh nghiệp đang chịu gánh nặng nợ quá mức, làm tăng đáng kể rủi ro vỡ nợ.\n",
    "\n",
    "#### Working Capital Efficiency\n",
    "\n",
    "Nhóm chỉ số này đánh giá hiệu quả quản lý vốn lưu động thông qua ba thành phần chính:\n",
    "\n",
    "**Days Sales Outstanding (DSO)** đo lường số ngày trung bình để thu hồi tiền từ khách hàng, được tính bằng (AR / Revenue) × 365. DSO tăng cao cho thấy doanh nghiệp gặp khó khăn trong việc thu hồi công nợ, có thể dẫn đến thiếu hụt tiền mặt.\n",
    "\n",
    "**Days Payables Outstanding (DPO)** đo lường số ngày trung bình doanh nghiệp trả tiền cho nhà cung cấp, được tính bằng (AP / COGS) × 365. DPO cao có thể là dấu hiệu tích cực (tận dụng tín dụng thương mại) hoặc tiêu cực (khó khăn thanh khoản).\n",
    "\n",
    "**Days On Hand (DOH)** đo lường số ngày tồn kho trung bình, được tính bằng (Inventory / COGS) × 365. DOH cao cho thấy hàng tồn kho nhiều, có thể làm gián đoạn dòng tiền.\n",
    "\n",
    "**Cash Conversion Cycle (CCC)** là chỉ số tổng hợp, được tính bằng DSO + DOH - DPO. CCC đo lường số ngày vốn bị \"đóng băng\" trong chu kỳ kinh doanh, từ khi trả tiền mua hàng đến khi thu được tiền từ khách hàng. CCC tăng cao cho thấy hiệu quả quản lý vốn lưu động kém, làm dòng tiền xấu đi.\n",
    "\n",
    "#### Trend Analysis (QoQ)\n",
    "\n",
    "Ngoài các chỉ số tĩnh, chúng ta còn tính toán xu hướng thay đổi theo quý (Quarter-over-Quarter) cho các chỉ số quan trọng. **delta_dso_qoq** và **delta_ccc_qoq** cho biết sự thay đổi của DSO và CCC so với quý trước, giúp phát hiện sớm các dấu hiệu xấu đi trong quản lý vốn lưu động."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef4b2b8",
   "metadata": {},
   "source": [
    "### B. Behavioral Features (Observation Window = 180 ngày)\n",
    "\n",
    "Các đặc trưng hành vi được trích xuất từ dữ liệu giao dịch hàng ngày trong 180 ngày gần nhất trước ngày đánh giá (as-of date). Những features này phản ánh hành vi sử dụng tín dụng thực tế của khách hàng, thường có sức mạnh dự đoán cao hơn so với các chỉ số tài chính truyền thống vì chúng nắm bắt được các vấn đề thanh khoản và khó khăn tài chính ngay khi chúng phát sinh.\n",
    "\n",
    "#### Credit Utilization\n",
    "\n",
    "Tỷ lệ sử dụng hạn mức tín dụng là chỉ số quan trọng phản ánh mức độ phụ thuộc của doanh nghiệp vào nguồn vốn vay ngân hàng. Chúng ta tính toán hai chỉ số chính:\n",
    "\n",
    "**%util_mean_60d** là tỷ lệ sử dụng hạn mức trung bình trong 60 ngày gần nhất, được tính bằng (Utilized / Limit) trung bình. Chỉ số này cho biết mức độ \"căng\" về thanh khoản của doanh nghiệp. Utilization rate vượt quá 85% cho thấy doanh nghiệp đang áp sát hạn mức, có nguy cơ thiếu thanh khoản nếu có bất kỳ cú sốc nào.\n",
    "\n",
    "**%util_p95_60d** là percentile thứ 95 của utilization trong 60 ngày, đo lường đỉnh sử dụng hạn mức. Chỉ số này quan trọng vì nó cho thấy trong những ngày \"xấu nhất\", doanh nghiệp sử dụng bao nhiêu phần trăm hạn mức, giúp phát hiện các giai đoạn căng thẳng thanh khoản tạm thời.\n",
    "\n",
    "#### Delinquency Patterns\n",
    "\n",
    "Days Past Due (DPD) là chỉ số trực tiếp nhất về khó khăn thanh toán. Chúng ta phân tích DPD theo nhiều góc độ:\n",
    "\n",
    "**dpd_max_180d** là số ngày quá hạn tối đa trong 180 ngày qua. Theo chuẩn mực ngành, DPD vượt quá 30 ngày được coi là early warning signal, trong khi DPD vượt 90 ngày là dấu hiệu rõ ràng của default risk theo định nghĩa Basel.\n",
    "\n",
    "**dpd_trend_180d** đo lường xu hướng của DPD theo thời gian bằng cách tính slope (hệ số góc) của đường hồi quy tuyến tính giữa DPD và thời gian. Slope dương cho thấy DPD đang có xu hướng tăng dần (tình hình xấu đi), trong khi slope âm cho thấy doanh nghiệp đang cải thiện khả năng thanh toán.\n",
    "\n",
    "**near_due_freq_7d** đo lường tần suất \"gần quá hạn\" trong 7 ngày gần nhất, được định nghĩa là tỷ lệ ngày có 0 < DPD < 30. Chỉ số này giúp phát hiện các khách hàng thường xuyên trễ hạn nhưng chưa đến mức quá hạn nghiêm trọng, đây là early warning quan trọng.\n",
    "\n",
    "#### Credit Limit Breach\n",
    "\n",
    "**limit_breach_cnt_90d** đếm số lần khách hàng vượt quá hạn mức tín dụng trong 90 ngày gần nhất. Bất kỳ lần vi phạm nào (> 0) đều là dấu hiệu cảnh báo nghiêm trọng, cho thấy doanh nghiệp có nhu cầu vốn vượt quá khả năng được phê duyệt, hoặc hệ thống kiểm soát nội bộ kém.\n",
    "\n",
    "---\n",
    "\n",
    "### C. Cashflow Features\n",
    "\n",
    "Dòng tiền là \"huyết mạch\" của doanh nghiệp, quan trọng hơn cả lợi nhuận kế toán trong việc dự đoán khả năng vỡ nợ. Chúng ta phân tích dòng tiền vào/ra hàng ngày trong 180 ngày qua để tạo các features:\n",
    "\n",
    "**inflow_mean_60d** và **outflow_mean_60d** là dòng tiền vào và ra trung bình trong 60 ngày gần nhất. Hai chỉ số này phản ánh quy mô và tính ổn định của hoạt động kinh doanh. Sự chênh lệch lớn giữa inflow và outflow (burn rate cao) là dấu hiệu cảnh báo.\n",
    "\n",
    "**inflow_drop_60d** đo lường tỷ lệ giảm của dòng tiền vào trong 60 ngày gần nhất so với median 6 tháng, được tính bằng (median_6m - mean_60d) / median_6m. Chỉ số này giúp phát hiện sớm sụt giảm doanh thu, một trong những nguyên nhân chính dẫn đến vỡ nợ. Inflow drop vượt quá 20% cho thấy dòng tiền đang giảm mạnh, cần có hành động can thiệp ngay lập tức.\n",
    "\n",
    "---\n",
    "\n",
    "### D. Covenant Breach Flags\n",
    "\n",
    "Covenant (điều khoản ràng buộc) là các ngưỡng tài chính mà khách hàng phải duy trì theo hợp đồng tín dụng. Vi phạm covenant là early warning signal cực kỳ quan trọng, thường xảy ra trước khi default thực sự diễn ra.\n",
    "\n",
    "Chúng ta theo dõi ba loại covenant chính: **breach_icr** (vi phạm ICR < 1.5), **breach_dscr** (vi phạm DSCR < 1.2), và **breach_leverage** (vi phạm Debt/EBITDA > 4.0). Mỗi breach flag là biến nhị phân (0/1), cho biết khách hàng có vi phạm covenant tương ứng hay không. Vi phạm bất kỳ covenant nào đều trigger các hành động như renegotiation, tightening điều kiện, hoặc tăng giám sát.\n",
    "\n",
    "---\n",
    "\n",
    "### E. Normalization (Sector-Size)\n",
    "\n",
    "Một trong những thách thức lớn nhất trong credit scoring là so sánh các doanh nghiệp khác nhau về quy mô và ngành nghề. Một SME trong ngành Retail có ICR = 2.0 có thể được coi là tốt, nhưng cùng chỉ số đó với một Large Corporate trong ngành IT lại là mức trung bình hoặc kém.\n",
    "\n",
    "Để giải quyết vấn đề này, chúng ta áp dụng **Z-score normalization** theo nhóm (Sector, Size_bucket). Mỗi feature được chuẩn hóa bằng cách so sánh với các khách hàng cùng ngành và cùng quy mô:\n",
    "\n",
    "```\n",
    "z_score = (value - median_group) / IQR_group\n",
    "```\n",
    "\n",
    "Chúng ta sử dụng **Median và IQR (Interquartile Range)** thay vì Mean và Standard Deviation vì chúng robust hơn với outliers, rất phổ biến trong dữ liệu tài chính. Features sau khi normalize có suffix `__zs_sector_size`, ví dụ: `icr_ttm__zs_sector_size`, `dpd_max_180d__zs_sector_size`.\n",
    "\n",
    "Normalization này mang lại hai lợi ích quan trọng: (1) So sánh công bằng giữa các doanh nghiệp cùng đặc điểm, và (2) Tăng sức mạnh dự đoán của model vì features được điều chỉnh theo context riêng của từng nhóm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Feature Engineering\n",
    "print(\"Command to create features:\")\n",
    "print(\"python src/feature_engineering.py --raw-dir data/raw --asof 2025-06-30 --outdir data/processed\")\n",
    "print(\"\\nKey features created:\")\n",
    "features = [\n",
    "    \"Financial: icr_ttm, dscr_ttm_proxy, debt_to_ebitda, current_ratio, dso, ccc\",\n",
    "    \"Behavioral: %util_mean_60d, dpd_max_180d, dpd_trend_180d, limit_breach_cnt_90d\",\n",
    "    \"Cashflow: inflow_mean_60d, inflow_drop_60d\",\n",
    "    \"Covenant: breach_icr, breach_dscr, breach_leverage\",\n",
    "    \"Normalized: *__zs_sector_size versions\"\n",
    "]\n",
    "for f in features:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1876c",
   "metadata": {},
   "source": [
    "## Step 3: Model Training & Calibration\n",
    "\n",
    "Module: `src/train_baseline.py`\n",
    "\n",
    "### Overview\n",
    "\n",
    "Bước này xây dựng mô hình Machine Learning để dự đoán xác suất vỡ nợ (PD) trong 12 tháng tới. Chúng ta sử dụng **LightGBM** làm classifier cơ sở vì khả năng xử lý tốt nhiều features, tự động học được các mối quan hệ phi tuyến, và hỗ trợ class balancing. Sau khi train, mô hình được **calibrate** bằng Isotonic Regression để đảm bảo predicted probabilities phản ánh đúng true probabilities - điều quan trọng cho credit risk management và tuân thủ Basel.\n",
    "\n",
    "---\n",
    "\n",
    "### A. LightGBM Configuration\n",
    "\n",
    "LightGBM được chọn vì xử lý tốt nhiều features có quy mô khác nhau (financial ratios, utilization rates, DPD counts), tự động học feature interactions (\"ICR thấp + Utilization cao = Rủi ro cao\"), và hỗ trợ class weighting cho imbalanced data (default rate ~5-10%).\n",
    "\n",
    "**Hyperparameters:**\n",
    "\n",
    "```python\n",
    "LGBMClassifier(\n",
    "    n_estimators=300,           # 300 cây trong ensemble\n",
    "    learning_rate=0.05,         # Học chậm nhưng ổn định\n",
    "    num_leaves=15,              # Giới hạn complexity\n",
    "    max_depth=6,                # Tránh overfitting\n",
    "    subsample=0.8,              # Row sampling (bagging)\n",
    "    colsample_bytree=0.8,       # Column sampling\n",
    "    min_child_samples=10,       # Mỗi leaf ≥ 10 samples\n",
    "    reg_lambda=0.1,             # L2 regularization\n",
    "    scale_pos_weight=(1-pos_rate)/pos_rate,  # Auto-balance classes\n",
    "    objective='binary',\n",
    "    random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "**Train-Test Split**: 80% training, 20% holdout test với stratified sampling để đảm bảo default rate đồng đều.\n",
    "\n",
    "---\n",
    "\n",
    "### B. Isotonic Calibration (CV=5)\n",
    "\n",
    "Gradient boosting models thường cho ra **uncalibrated probabilities** - khi model dự đoán PD = 20%, tỷ lệ thực tế default có thể là 15% hoặc 30%. Trong credit risk, điều này nguy hiểm vì các quyết định quan trọng (capital allocation, pricing, provisioning) dựa vào con số PD này.\n",
    "\n",
    "**Isotonic Regression** là phương pháp calibration non-parametric và monotonic, học hàm mapping từ raw probabilities sang calibrated probabilities với ràng buộc đơn điệu tăng (customer có raw PD cao hơn vẫn có calibrated PD cao hơn). Chúng ta sử dụng 5-fold CV để tránh overfitting:\n",
    "\n",
    "```python\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "calibrated_model = CalibratedClassifierCV(\n",
    "    base_lgbm,\n",
    "    method='isotonic',\n",
    "    cv=5\n",
    ")\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Isotonic Regression được ưu tiên hơn Platt Scaling vì: (1) Không giả định functional form (không cần sigmoid), (2) Đảm bảo ranking không đổi, (3) Performance tốt hơn với sample size lớn (≥ 1000 customers).\n",
    "\n",
    "---\n",
    "\n",
    "### C. Risk Tiers & Thresholds\n",
    "\n",
    "Sau calibration, customers được phân loại vào 3 risk tiers dựa trên **percentile-based thresholds** (thay vì absolute PD cutoffs) để quản lý capacity. Ngân hàng chỉ có đủ nguồn lực để quản lý chặt chẽ một số lượng customers high-risk nhất, nên việc cố định Red tier = top 5% đảm bảo số lượng customers cần intensive monitoring không vượt quá capacity.\n",
    "\n",
    "**Tier Definitions:**\n",
    "\n",
    "| Tier | Percentile | Typical PD | Action | Capacity |\n",
    "|------|-----------|-----------|--------|----------|\n",
    "| **Red** | Top 5% | ≥ 20% | Họp KH ≤5 ngày; lập cash flow 13 tuần; tighten covenants; watchlist | ~50 KH → 5 RMs |\n",
    "| **Amber** | Top 5-15% | 5-20% | Soát xét ≤10 ngày; yêu cầu management accounts; hạn chế hạn mức | ~100 KH → 10 RMs |\n",
    "| **Green** | Bottom 85% | < 5% | Theo dõi định kỳ quarterly; không cần hành động đặc biệt | Portfolio monitoring |\n",
    "\n",
    "**Threshold Calculation:**\n",
    "\n",
    "```python\n",
    "train_probs = calibrated_model.predict_proba(X_train)[:, 1]\n",
    "red_threshold = np.percentile(train_probs, 95)      # e.g., 0.23\n",
    "amber_threshold = np.percentile(train_probs, 85)    # e.g., 0.08\n",
    "```\n",
    "\n",
    "Thresholds được lưu vào `thresholds.json` và sử dụng nhất quán cho các lần scoring sau.\n",
    "\n",
    "---\n",
    "\n",
    "### D. Evaluation Metrics\n",
    "\n",
    "Model được đánh giá toàn diện qua nhiều metrics, mỗi metric đo lường một khía cạnh khác nhau:\n",
    "\n",
    "**1. AUC-ROC (Discrimination Power)**  \n",
    "Đo khả năng phân biệt defaulters vs non-defaulters. AUC = 0.80 nghĩa là 80% trường hợp model sẽ rank đúng (assign PD cao hơn cho defaulter). **Target**: ≥ 0.75 (industry standard).\n",
    "\n",
    "**2. PR-AUC (Precision-Recall)**  \n",
    "Quan trọng với imbalanced data (default rate thấp). Precision = % customers được dự đoán default thực sự default. Recall = % defaults thực tế được phát hiện. **Target**: ≥ 0.40 (với base rate ~8%).\n",
    "\n",
    "**3. KS Statistic (Kolmogorov-Smirnov)**  \n",
    "Đo maximum separation giữa cumulative distributions của defaulters và non-defaulters. KS = max(TPR - FPR). **Target**: ≥ 0.35 (good discriminatory power).\n",
    "\n",
    "**4. Brier Score (Calibration Quality)**  \n",
    "MSE của probabilities: `Brier = (1/N) × Σ(predicted_prob - actual_outcome)²`. Brier nhỏ nghĩa là predictions accurate (nếu dự đoán 10 KH mỗi người PD=20%, lý tưởng có 2 defaults). **Target**: ≤ 0.10. Brier giảm đáng kể sau calibration (từ ~0.12 xuống ~0.08).\n",
    "\n",
    "**5. Calibration Curve (Reliability Diagram)**  \n",
    "Visualize calibration: plot mean predicted probability vs actual default rate trong từng bin. Đường lý tưởng là y = x (diagonal).\n",
    "\n",
    "---\n",
    "\n",
    "### E. Outputs & Artifacts\n",
    "\n",
    "**1. Model File**: `model_lgbm.pkl` - Chứa base LightGBM, calibrated model, feature names, và metadata (training date, hyperparameters, test AUC, test Brier).\n",
    "\n",
    "**2. Scores**: `scores_all.csv` - Predictions cho toàn bộ dataset (train + test) với columns: `customer_id`, `prob_default_12m_base`, `prob_default_12m_calibrated`, `tier`, `is_test`.\n",
    "\n",
    "**3. Thresholds**: `thresholds.json` - Lưu red/amber/green thresholds và percentiles để dùng cho scoring sau này.\n",
    "\n",
    "**4. Visualizations**:\n",
    "- `calibration_lgbm.png`: Reliability diagram (before vs after calibration)\n",
    "- `pr_curve_lgbm.png`: Precision-Recall curve\n",
    "- `roc_curve_lgbm.png`: ROC curve  \n",
    "- `shap_summary.png`: Quick SHAP summary (top 10 features)\n",
    "\n",
    "Tất cả artifacts được version control để đảm bảo reproducibility và auditability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a43eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Train model\n",
    "print(\"Command to train LightGBM model:\")\n",
    "print(\"python src/train_baseline.py --features data/processed/feature_ews.parquet --test-size 0.2 --seed 42 --red-pct 0.05 --amber-pct 0.10 --outdir artifacts/models\")\n",
    "print(\"\\nOutputs:\")\n",
    "print(\"  - artifacts/models/model_lgbm.pkl (base + calibrated model + features)\")\n",
    "print(\"  - artifacts/models/scores_all.csv (predictions + tiers)\")\n",
    "print(\"  - artifacts/models/thresholds.json\")\n",
    "print(\"  - artifacts/models/calibration_lgbm.png\")\n",
    "print(\"  - artifacts/models/pr_curve_lgbm.png\")\n",
    "print(\"  - artifacts/models/shap_summary.csv/png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a18bb",
   "metadata": {},
   "source": [
    "## 🔍 Step 4: Model Explainability (SHAP)\n",
    "\n",
    "Module: `src/explain.py`\n",
    "\n",
    "### Overview\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) giải thích contribution của từng feature vào prediction dựa trên game theory. SHAP value dương nghĩa là feature đó tăng xác suất default, âm nghĩa là giảm default risk, và magnitude cho biết mức độ ảnh hưởng. Điều này quan trọng cho Credit Committee (giải thích decisions), RM Team (tư vấn customers cải thiện), và Model Validation (đảm bảo model học đúng patterns).\n",
    "\n",
    "---\n",
    "\n",
    "### Global Explainability\n",
    "\n",
    "**Feature Importance** (`feature_importance.csv`): Mean absolute SHAP values cho mỗi feature, cho biết features nào ảnh hưởng nhất đến model trong toàn bộ portfolio. Ví dụ, `dpd_max_180d__zs_sector_size` thường là feature quan trọng nhất vì DPD là signal mạnh nhất cho default risk.\n",
    "\n",
    "**SHAP Summary Plot** (`shap_summary.png`): Waterfall plot visualize impact của tất cả features. Mỗi điểm là một customer, màu đỏ = feature value cao, xanh = feature value thấp. Plot này cho thấy không chỉ feature nào quan trọng mà còn direction của impact (high DPD → high risk, high ICR → low risk).\n",
    "\n",
    "---\n",
    "\n",
    "### Local Explainability\n",
    "\n",
    "**Top Drivers per Customer** (`top_drivers_per_customer.csv`): Top 5 features quan trọng nhất cho từng customer cụ thể, giúp trả lời câu hỏi \"Tại sao customer C0042 được phân vào Red tier?\". Output bao gồm feature name, SHAP value, và actual feature value.\n",
    "\n",
    "Ví dụ cho customer C0042:\n",
    "1. `dpd_max_180d__zs_sector_size`: SHAP = +0.52 (value = 120 days) → DPD cao\n",
    "2. `%util_mean_60d__zs_sector_size`: SHAP = +0.31 (value = 0.95) → Utilization sát hạn mức\n",
    "3. `icr_ttm__zs_sector_size`: SHAP = +0.20 (value = 0.8) → ICR thấp, khó trả lãi\n",
    "\n",
    "Với thông tin này, RM có thể tư vấn customer: (1) Clear outstanding payments để giảm DPD, (2) Giảm credit usage hoặc apply for limit increase, (3) Cải thiện profitability hoặc restructure debt.\n",
    "\n",
    "---\n",
    "\n",
    "### Dependence Plots\n",
    "\n",
    "SHAP dependence plots cho key features (`icr_ttm`, `ccc`, `%util_mean_60d`) hiển thị mối quan hệ phi tuyến giữa feature value và SHAP value. Ví dụ, dependence plot của ICR có thể cho thấy: ICR < 1.5 có SHAP values rất cao (risk tăng mạnh), ICR 1.5-3.0 có SHAP giảm dần, ICR > 3.0 có SHAP gần 0 (không còn rủi ro thêm). Những insights này giúp validate model đang học đúng business logic.\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs Summary\n",
    "\n",
    "| File | Type | Purpose |\n",
    "|------|------|---------|\n",
    "| `feature_importance.csv` | Global | Ranking features by importance |\n",
    "| `shap_summary.png` | Global | Visual impact of all features |\n",
    "| `top_drivers_per_customer.csv` | Local | Top 5 drivers cho từng customer |\n",
    "| `shap_dependence_*.png` | Global | Phi tuyến relationships |\n",
    "| `summary.json` | Metadata | Config và stats |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66152533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate SHAP explanations\n",
    "print(\"Command to generate SHAP explanations:\")\n",
    "print(\"python src/explain.py --model artifacts/models/model_lgbm.pkl --features data/processed/feature_ews.parquet --outdir artifacts/shap --max-display 20\")\n",
    "print(\"\\nOutputs:\")\n",
    "print(\"  - artifacts/shap/feature_importance.csv\")\n",
    "print(\"  - artifacts/shap/shap_summary.png\")\n",
    "print(\"  - artifacts/shap/top_drivers_per_customer.csv\")\n",
    "print(\"  - artifacts/shap/shap_dependence_*.png\")\n",
    "print(\"  - artifacts/shap/summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121d40f",
   "metadata": {},
   "source": [
    "## ⚙️ Step 5-6: [Optional] Re-calibration\n",
    "\n",
    "### Why Optional?\n",
    "\n",
    "Bước 3 (train_baseline.py) đã tạo ra một **calibrated model** với percentile-based thresholds (Red = top 5%, Amber = top 5-15%) sẵn sàng cho production. Steps 5-6 chỉ cần thiết khi business muốn **thay đổi threshold strategy** từ percentile-based sang **absolute PD cutoffs** (ví dụ: Red ≥ 20% PD, Amber ≥ 5% PD) để phù hợp với risk appetite hoặc regulatory requirements cụ thể.\n",
    "\n",
    "Trong thực tế, percentile-based approach thường được ưu tiên vì đảm bảo số lượng customers cần intensive monitoring không vượt quá capacity. Tuy nhiên, một số tổ chức (đặc biệt banks tuân thủ Basel/IFRS 9) yêu cầu absolute thresholds để nhất quán với internal risk rating systems hoặc regulatory reporting.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Extract Raw Scores\n",
    "\n",
    "**Module**: `src/make_scores_raw.py`\n",
    "\n",
    "Trích xuất raw probabilities từ **base LightGBM** (trước khi áp dụng isotonic calibration trong Step 3) để có baseline scores cho re-calibration process. Output là `scores_raw.csv` chứa uncalibrated predictions cho toàn bộ dataset.\n",
    "\n",
    "**Why needed?** Re-calibration cần raw scores làm input vì chúng ta sẽ fit một calibrator mới với absolute thresholds khác với calibrator trong Step 3.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 6: Re-calibrate with Absolute Thresholds\n",
    "\n",
    "**Module**: `src/calibrate.py`\n",
    "\n",
    "Fit lại **Isotonic Regression** trên raw scores với absolute PD cutoffs thay vì percentiles. Process bao gồm: (1) Fit calibrator trên training set, (2) Map raw scores → calibrated PD, (3) Apply absolute thresholds (Red ≥ 20%, Amber ≥ 5%), (4) Save calibrator và thresholds.\n",
    "\n",
    "**Key difference from Step 3:**\n",
    "- Step 3: Calibrate → Calculate percentile thresholds → Tiers fixed by % (top 5%, 10%)\n",
    "- Step 6: Calibrate → Apply absolute PD thresholds → Tiers vary by portfolio quality\n",
    "\n",
    "**Outputs:**\n",
    "- `calibrator.pkl`: New isotonic calibrator\n",
    "- `mapping.csv`: Raw score → Calibrated PD mapping table\n",
    "- `thresholds.json`: Absolute cutoffs (red: 0.20, amber: 0.05)\n",
    "- `calibration_full.png`: Reliability diagram\n",
    "- `pr_curve_full.png`: Precision-Recall curve\n",
    "\n",
    "**Tradeoff:** Với absolute thresholds, số lượng customers trong Red/Amber tiers có thể biến động theo quality của portfolio (good period → ít Red, bad period → nhiều Red), gây khó khăn cho capacity planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3385969",
   "metadata": {},
   "source": [
    "## 🎯 Step 7: Production Scoring\n",
    "\n",
    "Module: `src/scoring.py`\n",
    "\n",
    "Scoring là bước cuối cùng để đưa model vào production. Script này load trained model, predict PD cho toàn bộ customers dựa trên feature snapshot tại as-of date (ví dụ: 2025-06-30), sau đó phân tier và đưa ra action recommendations. Output được sử dụng trực tiếp bởi RM team và Risk Committee để ra quyết định nghiệp vụ.\n",
    "\n",
    "---\n",
    "\n",
    "### Inputs & Outputs\n",
    "\n",
    "**Inputs:**\n",
    "1. **Features**: `data/processed/feature_ews.parquet` - Feature snapshot tại as-of date\n",
    "2. **Model**: `artifacts/models/model_lgbm.pkl` - Trained & calibrated LightGBM\n",
    "3. **Thresholds**: `artifacts/calibration/thresholds.json` hoặc `artifacts/models/thresholds.json` - Tùy approach (absolute vs percentile)\n",
    "\n",
    "**Output**: `ews_scored_YYYY-MM-DD.csv` với columns:\n",
    "\n",
    "| Column | Description | Example |\n",
    "|--------|-------------|---------|\n",
    "| `customer_id` | Customer identifier | C0042 |\n",
    "| `prob_default_12m_calibrated` | PD trong 12 tháng (0-1) | 0.2341 |\n",
    "| `score_ews` | EWS Score (0-100) | 76.59 |\n",
    "| `tier` | Risk tier | Red |\n",
    "| `action` | Recommended action | Họp KH ≤5 ngày; lập cash flow 13 tuần;... |\n",
    "\n",
    "**EWS Score Formula**: `100 × (1 - PD)` → Score cao = Rủi ro thấp (100 = tốt nhất, 0 = xấu nhất)\n",
    "\n",
    "---\n",
    "\n",
    "### Risk Tiers & Actions\n",
    "\n",
    "| Tier | Criteria | Action | Frequency |\n",
    "|------|----------|--------|-----------|\n",
    "| **Green** | PD < 5% (hoặc bottom 85%) | Theo dõi định kỳ; cập nhật BCTC đúng hạn | Quarterly |\n",
    "| **Amber** | 5% ≤ PD < 20% (hoặc top 5-15%) | Soát xét RM ≤10 ngày; yêu cầu management accounts; kiểm tra công nợ; hạn chế hạn mức | Monthly |\n",
    "| **Red** | PD ≥ 20% (hoặc top 5%) | Họp KH ≤5 ngày; lập cash flow 13 tuần; xem xét covenant tightening/collateral; watchlist | Weekly |\n",
    "\n",
    "**Note**: Criteria phụ thuộc vào threshold approach (absolute vs percentile) được chọn ở Steps 3 hoặc 5-6.\n",
    "\n",
    "---\n",
    "\n",
    "### Production Workflow\n",
    "\n",
    "**Monthly Cadence**:\n",
    "1. **Last day of month**: Chạy scoring script với as-of date = month-end\n",
    "2. **Day 1-2**: Phân phối report cho RM team và Risk Committee\n",
    "3. **Day 3-10**: RMs thực hiện actions theo tier (Amber reviews, Red meetings)\n",
    "4. **Throughout month**: Track action completion và update customer status\n",
    "\n",
    "**Integration với Banking Systems**:\n",
    "- **Input**: Features từ core banking system (financial data, credit transactions, cashflow)\n",
    "- **Output**: EWS scores import vào CRM/Credit Risk systems\n",
    "- **Alerts**: Auto-trigger emails/notifications cho customers chuyển sang Red tier\n",
    "\n",
    "**Monitoring**: Track tier migrations month-over-month để identify portfolio trends (improving/deteriorating)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6774e35",
   "metadata": {},
   "source": [
    "## 📊 Model Performance & Validation\n",
    "\n",
    "### Expected Performance Metrics (Holdout 20%)\n",
    "\n",
    "Model được đánh giá trên holdout test set với các metrics sau (computed trong `train_baseline.py` lines 99-104):\n",
    "\n",
    "| Metric | Target Range | Ý nghĩa | Code |\n",
    "|--------|-------------|---------|------|\n",
    "| **AUC-ROC** | 0.75 - 0.85 | Khả năng phân biệt defaulters vs non-defaulters | `roc_auc_score(y_te, p_te)` |\n",
    "| **PR-AUC** | 0.40 - 0.60 | Performance trên positive class (quan trọng với imbalanced data) | `average_precision_score(y_te, p_te)` |\n",
    "| **KS Statistic** | 0.35 - 0.50 | Maximum separation giữa cumulative distributions | `ks_score(y_te, p_te)` |\n",
    "| **Brier Score** | 0.05 - 0.10 | Calibration quality (lower is better) | `brier_score_loss(y_te, p_te)` |\n",
    "\n",
    "**Calibration Quality**: Reliability curve (predicted probabilities vs actual default rates) nên gần diagonal (y = x). Isotonic calibration cải thiện đáng kể metric này, thường giảm Brier score từ ~0.12 xuống ~0.08. Plots được generate trong `plot_calibration_pr()` function (lines 47-61).\n",
    "\n",
    "**Precision-Recall Tradeoff**: Red threshold (PD ≥ 20%) có high precision, moderate recall; Amber threshold (PD ≥ 5%) có balanced precision-recall.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Monitoring & Maintenance\n",
    "\n",
    "**Quarterly Reviews** (cần tự implement monitoring scripts):\n",
    "1. **Performance drift**: Monitor AUC, KS trên new data (target: không giảm > 5%)\n",
    "   - Re-run `train_baseline.py` trên new data và compare metrics\n",
    "2. **Population Stability Index (PSI)**: Đo distribution shift của features (target: PSI < 0.15)\n",
    "   - Formula: `PSI = Σ(actual% - expected%) × ln(actual%/expected%)`\n",
    "3. **Feature stability**: Check data quality, missing values, outliers\n",
    "   - Sử dụng data profiling tools hoặc pandas `.describe()`\n",
    "4. **Recalibration**: Nếu Brier score tăng > 0.10, consider re-fit calibrator\n",
    "   - Re-run Step 6 (`calibrate.py`) với data mới\n",
    "\n",
    "**Red Flags Trigger Retraining**:\n",
    "- AUC drops below 0.70\n",
    "- Brier score > 0.15\n",
    "- Large prediction shifts without business explanation (e.g., 10% customers chuyển tier bất thường)\n",
    "- PSI > 0.25 (severe distribution shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe319a76",
   "metadata": {},
   "source": [
    "## Feature Importance Ranking\n",
    "\n",
    "Dựa trên SHAP analysis trong `explain.py`, đây là 10 features có impact mạnh nhất đến dự báo default:\n",
    "\n",
    "| # | Feature Name | Category | Business Interpretation |\n",
    "|---|--------------|----------|------------------------|\n",
    "| 1 | `dpd_max_180d__zs_sector_size` | Behavioral | DPD tối đa trong 6 tháng - signal mạnh nhất cho default risk |\n",
    "| 2 | `%util_mean_60d__zs_sector_size` | Behavioral | Credit utilization trung bình - phản ánh liquidity stress |\n",
    "| 3 | `icr_ttm__zs_sector_size` | Financial | Interest Coverage Ratio - khả năng trả lãi vay |\n",
    "| 4 | `debt_to_ebitda__zs_sector_size` | Financial | Financial leverage - mức độ đòn bẩy tài chính |\n",
    "| 5 | `ccc__zs_sector_size` | Financial | Cash Conversion Cycle - hiệu quả quản lý vốn lưu động |\n",
    "| 6 | `inflow_drop_60d__zs_sector_size` | Cashflow | Mức giảm doanh thu - suy giảm cashflow |\n",
    "| 7 | `dpd_trend_180d__zs_sector_size` | Behavioral | Xu hướng DPD tăng - payment behavior đang xấu đi |\n",
    "| 8 | `breach_icr` | Covenant | Vi phạm covenant ICR - trigger event trực tiếp |\n",
    "| 9 | `current_ratio__zs_sector_size` | Financial | Current Ratio < 1.0 - nguy cơ thanh khoản ngắn hạn |\n",
    "| 10 | `delta_ccc_qoq__zs_sector_size` | Financial | Thay đổi CCC theo quý - efficiency đang giảm |\n",
    "\n",
    "### Phân tích theo Category\n",
    "\n",
    "- **Behavioral (40%)**: Payment patterns thực tế là predictor mạnh nhất - DPD history và utilization cho signal sớm nhất về khó khăn tài chính\n",
    "- **Financial (35%)**: Các chỉ số tài chính fundamental (ICR, leverage, liquidity ratios) quan trọng thứ hai\n",
    "- **Cashflow (15%)**: Revenue trends và cashflow dynamics detect deterioration sớm hơn báo cáo tài chính\n",
    "- **Covenant (10%)**: Breach events có impact đáng kể nhưng xuất hiện muộn hơn\n",
    "\n",
    "**Kết luận**: Model ưu tiên behavioral signals vì payment difficulties xuất hiện trước khi financial statements phản ánh đầy đủ. Điều này phù hợp với thực tế risk management trong credit monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4792cd",
   "metadata": {},
   "source": [
    "## 🚀 Complete End-to-End Pipeline\n",
    "\n",
    "### Full Workflow (Development)\n",
    "\n",
    "```bash\n",
    "# Step 1: Generate synthetic data\n",
    "python src/generate_data.py --n-customers 1000 --output-dir data/raw\n",
    "\n",
    "# Step 2: Feature engineering\n",
    "python src/feature_engineering.py --raw-dir data/raw --asof 2025-06-30 --outdir data/processed\n",
    "\n",
    "# Step 3: Train model + calibration\n",
    "python src/train_baseline.py --features data/processed/feature_ews.parquet --test-size 0.2 --seed 42 --red-pct 0.05 --amber-pct 0.10 --outdir artifacts/models\n",
    "\n",
    "# Step 4: Generate SHAP explanations\n",
    "python src/explain.py --model artifacts/models/model_lgbm.pkl --features data/processed/feature_ews.parquet --outdir artifacts/shap --max-display 20\n",
    "\n",
    "# [Optional] Step 5-6: Re-calibration with absolute thresholds\n",
    "python src/make_scores_raw.py --features data/processed/feature_ews.parquet --model artifacts/models/model_lgbm.pkl --out data/processed/scores_raw.csv\n",
    "python src/calibrate.py --input data/processed/scores_raw.csv --red-thr 0.20 --amber-thr 0.05 --outdir artifacts/calibration\n",
    "\n",
    "# Step 7: Production scoring\n",
    "python src/scoring.py --features data/processed/feature_ews.parquet --model artifacts/models/model_lgbm.pkl --thresholds artifacts/calibration/thresholds.json --asof 2025-06-30 --outdir artifacts/scoring\n",
    "```\n",
    "\n",
    "### Or use Makefile (if configured)\n",
    "\n",
    "```bash\n",
    "make requirements    # Install dependencies\n",
    "make lint           # Check code quality\n",
    "make format         # Format code with ruff\n",
    "make test          # Run pytest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700863f",
   "metadata": {},
   "source": [
    "## 💼 Business Use Cases\n",
    "\n",
    "### 1. Portfolio Review Meeting (Monthly)\n",
    "\n",
    "**Input:** `ews_scored_YYYY-MM-DD.csv`\n",
    "\n",
    "**Analysis:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "scores = pd.read_csv('artifacts/scoring/ews_scored_2025-06-30.csv')\n",
    "\n",
    "# Portfolio distribution\n",
    "print(scores['tier'].value_counts())\n",
    "# Green: 850 customers (85%)\n",
    "# Amber: 100 customers (10%)\n",
    "# Red:    50 customers (5%)\n",
    "\n",
    "# High-risk customers requiring immediate action\n",
    "red_tier = scores[scores['tier'] == 'Red'].sort_values('prob_default_12m_calibrated', ascending=False)\n",
    "print(f\"Red tier: {len(red_tier)} customers with avg PD = {red_tier['prob_default_12m_calibrated'].mean():.1%}\")\n",
    "```\n",
    "\n",
    "**Actions:**\n",
    "- **Red tier:** Immediate RM meeting + action plan\n",
    "- **Amber tier:** Enhanced monitoring + covenant review\n",
    "- **Green tier:** Standard periodic review\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Credit Approval Process\n",
    "\n",
    "**New loan application từ khách hàng C0523:**\n",
    "\n",
    "```python\n",
    "# Get customer's EWS score\n",
    "customer = scores[scores['customer_id'] == 'C0523'].iloc[0]\n",
    "print(f\"Customer C0523:\")\n",
    "print(f\"  - EWS Score: {customer['score_ews']}\")\n",
    "print(f\"  - PD 12M: {customer['prob_default_12m_calibrated']:.1%}\")\n",
    "print(f\"  - Tier: {customer['tier']}\")\n",
    "print(f\"  - Action: {customer['action']}\")\n",
    "\n",
    "# Decision rule\n",
    "if customer['tier'] == 'Red':\n",
    "    print(\"REJECT or require additional collateral\")\n",
    "elif customer['tier'] == 'Amber':\n",
    "    print(\"APPROVE with covenant tightening\")\n",
    "else:\n",
    "    print(\"APPROVE standard terms\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Early Intervention\n",
    "\n",
    "**Identify deteriorating customers:**\n",
    "\n",
    "```python\n",
    "# Compare current month vs last month\n",
    "current = pd.read_csv('artifacts/scoring/ews_scored_2025-06-30.csv')\n",
    "previous = pd.read_csv('artifacts/scoring/ews_scored_2025-05-31.csv')\n",
    "\n",
    "merged = current.merge(previous, on='customer_id', suffixes=('_current', '_previous'))\n",
    "merged['pd_change'] = merged['prob_default_12m_calibrated_current'] - merged['prob_default_12m_calibrated_previous']\n",
    "\n",
    "# Customers with PD increasing by > 10pp\n",
    "deteriorating = merged[merged['pd_change'] > 0.10].sort_values('pd_change', ascending=False)\n",
    "print(f\"Deteriorating customers: {len(deteriorating)}\")\n",
    "```\n",
    "\n",
    "**Trigger actions:**\n",
    "- Request updated financials\n",
    "- Schedule RM meeting\n",
    "- Review credit limits\n",
    "\n",
    "---\n",
    "\n",
    "### 4. SHAP-based Customer Advisory\n",
    "\n",
    "**Why is customer C0042 in Red tier?**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load SHAP drivers\n",
    "drivers = pd.read_csv('artifacts/shap/top_drivers_per_customer.csv')\n",
    "customer_drivers = drivers[drivers['customer_id'] == 'C0042'].iloc[0]\n",
    "\n",
    "print(\"Top 3 risk drivers:\")\n",
    "for i in range(1, 4):\n",
    "    print(f\"{i}. {customer_drivers[f'feat{i}']}: {customer_drivers[f'shap{i}']:.3f} (value={customer_drivers[f'value{i}']})\")\n",
    "\n",
    "# Output:\n",
    "# 1. dpd_max_180d__zs_sector_size: 0.523 (value=120)\n",
    "# 2. %util_mean_60d__zs_sector_size: 0.312 (value=0.95)\n",
    "# 3. icr_ttm__zs_sector_size: 0.201 (value=0.8)\n",
    "```\n",
    "\n",
    "**RM Advice to customer:**\n",
    "1. **DPD 120 days:** Clear outstanding payments immediately\n",
    "2. **95% utilization:** Reduce credit line usage or apply for limit increase\n",
    "3. **ICR 0.8:** Improve profitability or restructure debt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1732f",
   "metadata": {},
   "source": [
    "## 📈 Artifacts & Outputs Summary\n",
    "\n",
    "### Directory Structure\n",
    "\n",
    "```\n",
    "artifacts/\n",
    "├── models/\n",
    "│   ├── model_lgbm.pkl              # Trained model (base + calibrated + features)\n",
    "│   ├── scores_all.csv              # Training set predictions + tiers\n",
    "│   ├── thresholds.json             # Percentile-based thresholds\n",
    "│   ├── calibration_lgbm.png        # Reliability diagram\n",
    "│   ├── pr_curve_lgbm.png           # Precision-Recall curve\n",
    "│   └── shap_summary.csv/png        # Quick SHAP summary\n",
    "│\n",
    "├── calibration/\n",
    "│   ├── calibrator.pkl              # Isotonic calibrator (re-fitted)\n",
    "│   ├── mapping.csv                 # Raw score → Calibrated PD mapping\n",
    "│   ├── thresholds.json             # Absolute PD thresholds (Red ≥20%, Amber ≥5%)\n",
    "│   ├── calibration_full.png        # Reliability curve (re-calibrated)\n",
    "│   └── pr_curve_full.png           # PR curve (re-calibrated)\n",
    "│\n",
    "├── shap/\n",
    "│   ├── feature_importance.csv      # Global feature importance (mean |SHAP|)\n",
    "│   ├── shap_summary.png            # SHAP waterfall plot\n",
    "│   ├── top_drivers_per_customer.csv # Local explanations (top 5 features per customer)\n",
    "│   ├── shap_dependence_*.png       # Dependence plots for key features\n",
    "│   └── summary.json                # Metadata\n",
    "│\n",
    "└── scoring/\n",
    "    ├── ews_scored_2025-06-30.csv   # Production scores (customer_id, PD, score, tier, action)\n",
    "    └── thresholds_used.json        # Thresholds applied in this run\n",
    "```\n",
    "\n",
    "### Key Files for Different Stakeholders\n",
    "\n",
    "| Stakeholder | Key Files |\n",
    "|-------------|-----------|\n",
    "| **Risk Manager** | `ews_scored_*.csv`, `top_drivers_per_customer.csv` |\n",
    "| **Credit Committee** | `scores_all.csv`, `shap_summary.png`, `pr_curve_lgbm.png` |\n",
    "| **Data Scientist** | `model_lgbm.pkl`, `feature_importance.csv`, all plots |\n",
    "| **Model Validator** | `calibration_*.png`, `thresholds.json`, metrics in console output |\n",
    "| **Auditor** | All artifacts + `summary.json` for traceability |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b992b",
   "metadata": {},
   "source": [
    "## 🔬 Technical Deep Dives\n",
    "\n",
    "### 1. Why Isotonic Calibration?\n",
    "\n",
    "**Problem with raw LightGBM probabilities:**\n",
    "- Overconfident near 0 and 1\n",
    "- Not well-calibrated for credit risk (regulatory requirement)\n",
    "\n",
    "**Isotonic Regression:**\n",
    "- Non-parametric, monotonic calibration\n",
    "- Preserves ranking (AUC unchanged)\n",
    "- Improves Brier score and reliability\n",
    "\n",
    "**Alternative: Platt Scaling (Logistic Regression)**\n",
    "- Parametric (assumes sigmoid relationship)\n",
    "- Less flexible than Isotonic\n",
    "- Use if you need smooth curve\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Class Imbalance Handling\n",
    "\n",
    "**Default rate ~5-10%** → Highly imbalanced\n",
    "\n",
    "**Strategies applied:**\n",
    "1. **`scale_pos_weight`** in LightGBM\n",
    "   - Automatically weights positive class\n",
    "   - Formula: `(n_negative / n_positive)`\n",
    "   \n",
    "2. **Evaluation metrics:** PR-AUC instead of just ROC-AUC\n",
    "   - ROC-AUC can be misleading with imbalanced data\n",
    "   \n",
    "3. **Threshold tuning:** Separate from 0.5\n",
    "   - Red/Amber thresholds based on business capacity\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Feature Normalization (Sector-Size)\n",
    "\n",
    "**Why normalize by (Sector, Size)?**\n",
    "\n",
    "```python\n",
    "# Example: ICR = 2.0 for a SME in Retail\n",
    "# Is this good or bad?\n",
    "\n",
    "# Without normalization: Compare to all companies → Looks average\n",
    "# With sector-size normalization: Compare to SME Retailers → Looks good!\n",
    "\n",
    "# Implementation:\n",
    "def sector_size_normalize(df, cols):\n",
    "    for c in cols:\n",
    "        grouped = df.groupby(['sector_code', 'size_bucket'])\n",
    "        median = grouped[c].transform('median')\n",
    "        iqr = grouped[c].transform(lambda x: x.quantile(0.75) - x.quantile(0.25))\n",
    "        df[f'{c}__zs_sector_size'] = (df[c] - median) / iqr\n",
    "    return df\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Fair comparison (SME vs SME, Corp vs Corp, same sector)\n",
    "- Robust to outliers (median/IQR instead of mean/std)\n",
    "- Better predictive power\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Label Definition: Event Horizon = 12 Months\n",
    "\n",
    "**Basel Standard:** PD typically measured over 12-month horizon\n",
    "\n",
    "**Label rule:**\n",
    "```python\n",
    "# Default if: DPD ≥ 90 days for at least 30 consecutive days in next 12M\n",
    "dpd_90_plus_days = sum(dpd >= 90 for dpd in future_dpd_sequence)\n",
    "event_h12m = 1 if dpd_90_plus_days >= 30 else 0\n",
    "```\n",
    "\n",
    "**Rationale:**\n",
    "- 90 DPD: Industry standard for \"default\"\n",
    "- 30 consecutive days: Avoid transient spikes\n",
    "- 12M horizon: Align with regulatory reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aecc20",
   "metadata": {},
   "source": [
    "## 🎓 Basel & Regulatory Alignment\n",
    "\n",
    "### Basel Framework Compliance\n",
    "\n",
    "**1. PD (Probability of Default) Estimation**\n",
    "- ✅ 12-month horizon (Basel standard)\n",
    "- ✅ Through-the-cycle (TTC) calibration via Isotonic Regression\n",
    "- ✅ Backtesting with holdout set\n",
    "\n",
    "**2. Key Financial Ratios**\n",
    "- ✅ **ICR (Interest Coverage Ratio):** EBIT / Interest\n",
    "- ✅ **DSCR (Debt Service Coverage Ratio):** (EBITDA - CAPEX) / Debt Service\n",
    "- ✅ **Leverage Ratio:** Total Debt / EBITDA\n",
    "- ✅ **Liquidity Ratio:** Current Assets / Current Liabilities\n",
    "\n",
    "**3. Early Warning Indicators**\n",
    "- ✅ DPD tracking (30, 60, 90+ days)\n",
    "- ✅ Credit limit breach monitoring\n",
    "- ✅ Covenant breach flags\n",
    "- ✅ Cashflow deterioration signals\n",
    "\n",
    "**4. Model Governance**\n",
    "- ✅ **Explainability:** SHAP for transparency\n",
    "- ✅ **Calibration:** Reliability curves\n",
    "- ✅ **Validation:** AUC, KS, Brier on holdout\n",
    "- ✅ **Documentation:** All artifacts saved with metadata\n",
    "\n",
    "---\n",
    "\n",
    "### Risk Appetite Framework\n",
    "\n",
    "**Tier Definitions aligned with Risk Appetite:**\n",
    "\n",
    "| Tier | PD Range | Portfolio Allocation | Risk Appetite |\n",
    "|------|----------|---------------------|---------------|\n",
    "| Green | < 5% | 85% | Accept: Standard monitoring |\n",
    "| Amber | 5-20% | 10% | Tolerate: Enhanced monitoring |\n",
    "| Red | ≥ 20% | 5% | Mitigate/Exit: Immediate action |\n",
    "\n",
    "**Capacity Management:**\n",
    "- Red tier (5%): Max ~50 customers → 5 FTE RM (10 customers/RM)\n",
    "- Amber tier (10%): Max ~100 customers → 10 FTE RM (10 customers/RM)\n",
    "- Green tier (85%): Portfolio monitoring only\n",
    "\n",
    "---\n",
    "\n",
    "### Regulatory Reporting\n",
    "\n",
    "**Outputs compatible with:**\n",
    "- **IFRS 9:** Expected Credit Loss (ECL) calculation\n",
    "  - PD × LGD × EAD = ECL\n",
    "  - Model provides PD component\n",
    "  \n",
    "- **Basel II/III:** Internal Ratings-Based (IRB) approach\n",
    "  - PD model for corporate exposures\n",
    "  - Complement with LGD and EAD models\n",
    "  \n",
    "- **Stress Testing:** Scenario-based PD adjustments\n",
    "  - Re-run model with stressed features\n",
    "  - Example: Revenue shock, Interest rate shock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd156561",
   "metadata": {},
   "source": [
    "## 🛠️ Development & Deployment\n",
    "\n",
    "### Local Development Setup\n",
    "\n",
    "```bash\n",
    "# 1. Clone repository\n",
    "git clone https://github.com/dylanng3/corporate-credit-ews.git\n",
    "cd corporate-credit-ews\n",
    "\n",
    "# 2. Create virtual environment (Python 3.13)\n",
    "python -m venv .venv\n",
    ".venv\\Scripts\\activate  # Windows\n",
    "source .venv/bin/activate  # Linux/Mac\n",
    "\n",
    "# 3. Install dependencies\n",
    "pip install -U pip\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# 4. Run linting\n",
    "make lint\n",
    "\n",
    "# 5. Format code\n",
    "make format\n",
    "\n",
    "# 6. Run tests\n",
    "make test\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Testing Strategy\n",
    "\n",
    "**Unit Tests (`tests/test_data.py`):**\n",
    "```python\n",
    "def test_feature_engineering():\n",
    "    \"\"\"Test feature calculation logic\"\"\"\n",
    "    # Load sample data\n",
    "    # Compute features\n",
    "    # Assert feature values are correct\n",
    "\n",
    "def test_model_inference():\n",
    "    \"\"\"Test model scoring pipeline\"\"\"\n",
    "    # Load trained model\n",
    "    # Score test cases\n",
    "    # Assert outputs are valid probabilities [0, 1]\n",
    "```\n",
    "\n",
    "**Integration Tests:**\n",
    "- End-to-end pipeline test\n",
    "- Data → Features → Model → Scores\n",
    "\n",
    "---\n",
    "\n",
    "### Production Deployment Options\n",
    "\n",
    "**Option 1: Batch Scoring (Recommended)**\n",
    "```bash\n",
    "# Cron job: Monthly on last day of month\n",
    "0 23 L * * python src/scoring.py --features <path> --model <path> --asof $(date +%Y-%m-%d) --outdir artifacts/scoring\n",
    "```\n",
    "\n",
    "**Option 2: REST API (Real-time)**\n",
    "```python\n",
    "from fastapi import FastAPI\n",
    "import joblib\n",
    "\n",
    "app = FastAPI()\n",
    "model = joblib.load('artifacts/models/model_lgbm.pkl')\n",
    "\n",
    "@app.post('/predict')\n",
    "def predict(features: dict):\n",
    "    X = prepare_features(features)\n",
    "    prob = model.predict_proba(X)[:, 1][0]\n",
    "    tier = assign_tier(prob)\n",
    "    return {'prob': prob, 'tier': tier}\n",
    "```\n",
    "\n",
    "**Option 3: Airflow DAG (Orchestration)**\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "\n",
    "dag = DAG('ews_monthly', schedule_interval='0 0 L * *')\n",
    "\n",
    "generate_features = BashOperator(\n",
    "    task_id='generate_features',\n",
    "    bash_command='python src/feature_engineering.py ...'\n",
    ")\n",
    "\n",
    "score_customers = BashOperator(\n",
    "    task_id='score_customers',\n",
    "    bash_command='python src/scoring.py ...'\n",
    ")\n",
    "\n",
    "generate_features >> score_customers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Model Versioning\n",
    "\n",
    "**Recommended: MLflow or DVC**\n",
    "```bash\n",
    "# Track model with MLflow\n",
    "mlflow.log_model(model, 'lgbm_ews_v1')\n",
    "mlflow.log_metrics({'auc': 0.82, 'ks': 0.45})\n",
    "mlflow.log_artifacts('artifacts/models')\n",
    "\n",
    "# Or version with DVC\n",
    "dvc add artifacts/models/model_lgbm.pkl\n",
    "git add artifacts/models/model_lgbm.pkl.dvc\n",
    "git commit -m \"Model v1.0 - AUC 0.82\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce714d6f",
   "metadata": {},
   "source": [
    "## 📚 Future Enhancements\n",
    "\n",
    "### 1. Model Improvements\n",
    "\n",
    "**Advanced Models:**\n",
    "- ✨ **XGBoost:** Alternative to LightGBM (may perform better)\n",
    "- ✨ **Neural Networks:** TabNet, FT-Transformer for tabular data\n",
    "- ✨ **Ensemble:** Stack LightGBM + XGBoost + Logistic Regression\n",
    "\n",
    "**Feature Engineering:**\n",
    "- ✨ **Macro variables:** GDP growth, interest rate, sector indices\n",
    "- ✨ **Time-series features:** ARIMA residuals, trend slopes\n",
    "- ✨ **Text features:** NLP on management discussions, news sentiment\n",
    "- ✨ **Network features:** Supply chain relationships, customer concentration\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Sources\n",
    "\n",
    "**External Data Integration:**\n",
    "- 📊 **Credit Bureau:** Payment history from other banks\n",
    "- 📊 **Market Data:** Stock price (if listed), bond spreads\n",
    "- 📊 **Alternative Data:** Social media sentiment, web traffic\n",
    "- 📊 **Geospatial:** Location risk (flood zones, economic zones)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Interpretability Enhancements\n",
    "\n",
    "**Beyond SHAP:**\n",
    "- 📖 **LIME:** Local surrogate models\n",
    "- 📖 **Counterfactuals:** \"If ICR increased by 0.5, tier would change from Red to Amber\"\n",
    "- 📖 **Rule extraction:** Decision trees from LightGBM for simple rules\n",
    "- 📖 **Narrative generation:** Auto-generate credit memos\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Operational Features\n",
    "\n",
    "**Dashboard (Streamlit/Dash):**\n",
    "```python\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "st.title(\"Corporate Credit EWS Dashboard\")\n",
    "\n",
    "scores = pd.read_csv('artifacts/scoring/ews_scored_latest.csv')\n",
    "\n",
    "# Tier distribution pie chart\n",
    "st.plotly_chart(px.pie(scores, names='tier'))\n",
    "\n",
    "# Customer search\n",
    "customer_id = st.text_input(\"Customer ID\")\n",
    "if customer_id:\n",
    "    customer = scores[scores['customer_id'] == customer_id]\n",
    "    st.metric(\"EWS Score\", customer['score_ews'].iloc[0])\n",
    "    st.metric(\"PD 12M\", f\"{customer['prob_default_12m_calibrated'].iloc[0]:.1%}\")\n",
    "```\n",
    "\n",
    "**Alerting System:**\n",
    "- Email/Slack alerts when customer moves to Red tier\n",
    "- Weekly summary of tier migrations\n",
    "- Covenant breach notifications\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Model Monitoring\n",
    "\n",
    "**Drift Detection:**\n",
    "- **Population Stability Index (PSI):** Track feature distributions\n",
    "- **Model Performance Tracking:** AUC, KS on rolling windows\n",
    "- **Prediction Stability:** Variance of predictions month-over-month\n",
    "\n",
    "**Auto-retraining:**\n",
    "- Trigger retraining if PSI > 0.15 or AUC drops > 5%\n",
    "- A/B test new model vs production model\n",
    "- Gradual rollout with champion-challenger strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055acd37",
   "metadata": {},
   "source": [
    "## 📖 References & Resources\n",
    "\n",
    "### Academic & Industry Papers\n",
    "\n",
    "1. **Basel Committee on Banking Supervision**\n",
    "   - [Basel II: International Convergence of Capital Measurement](https://www.bis.org/publ/bcbs128.htm)\n",
    "   - PD, LGD, EAD estimation frameworks\n",
    "   \n",
    "2. **IFRS 9 - Expected Credit Loss**\n",
    "   - 12-month vs Lifetime PD\n",
    "   - Staging models (Stage 1, 2, 3)\n",
    "\n",
    "3. **Altman Z-Score (1968)**\n",
    "   - Classic credit scoring model for manufacturing firms\n",
    "   - Foundation for many modern models\n",
    "\n",
    "4. **SHAP: Lundberg & Lee (2017)**\n",
    "   - [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)\n",
    "   - Game-theoretic feature attribution\n",
    "\n",
    "---\n",
    "\n",
    "### Tools & Libraries\n",
    "\n",
    "**Python Packages:**\n",
    "- `lightgbm`: Gradient boosting framework\n",
    "- `shap`: Model explainability\n",
    "- `scikit-learn`: ML utilities, calibration\n",
    "- `pandas`, `numpy`: Data manipulation\n",
    "- `matplotlib`, `seaborn`, `plotly`: Visualization\n",
    "\n",
    "**Development:**\n",
    "- `ruff`: Fast Python linter & formatter\n",
    "- `pytest`: Testing framework\n",
    "- `cookiecutter-data-science`: Project template\n",
    "\n",
    "---\n",
    "\n",
    "### Credit Risk Resources\n",
    "\n",
    "**Books:**\n",
    "- *Credit Risk Modeling* by David Lando\n",
    "- *The Credit Scoring Toolkit* by Raymond Anderson\n",
    "- *Machine Learning for Asset Managers* by Marcos López de Prado\n",
    "\n",
    "**Online Courses:**\n",
    "- Coursera: *Credit Risk Modeling in Python*\n",
    "- Udemy: *Credit Risk Analytics with Python*\n",
    "\n",
    "**Websites:**\n",
    "- [Risk.net](https://www.risk.net) - Industry news\n",
    "- [Kaggle Credit Risk Datasets](https://www.kaggle.com/search?q=credit+risk)\n",
    "\n",
    "---\n",
    "\n",
    "### Contact & Support\n",
    "\n",
    "**Project Maintainer:** Duong N.C.K  \n",
    "**Repository:** [github.com/dylanng3/corporate-credit-ews](https://github.com/dylanng3/corporate-credit-ews)  \n",
    "**License:** MIT License\n",
    "\n",
    "**For questions or contributions:**\n",
    "- Open an issue on GitHub\n",
    "- Submit a pull request\n",
    "- Email: [contact info if available]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6545e",
   "metadata": {},
   "source": [
    "## 🎯 Summary & Conclusion\n",
    "\n",
    "### What We Built\n",
    "\n",
    "A **production-ready Early Warning System** for corporate credit risk with:\n",
    "\n",
    "✅ **End-to-end ML pipeline** (data → features → model → scoring → explainability)  \n",
    "✅ **Basel-aligned methodology** (12M PD, ICR, DSCR, leverage ratios)  \n",
    "✅ **LightGBM + Isotonic Calibration** (AUC ~0.75-0.85, well-calibrated probabilities)  \n",
    "✅ **SHAP explainability** (global + local feature importance)  \n",
    "✅ **3-tier risk classification** (Green/Amber/Red with actionable recommendations)  \n",
    "✅ **Production scoring pipeline** (batch scoring with thresholds)  \n",
    "✅ **Comprehensive artifacts** (models, scores, plots, metadata)\n",
    "\n",
    "---\n",
    "\n",
    "### Key Strengths\n",
    "\n",
    "1. **Comprehensive Feature Engineering**\n",
    "   - Financial ratios (ICR, DSCR, Leverage, CCC)\n",
    "   - Behavioral signals (DPD, utilization, trends)\n",
    "   - Cashflow monitoring\n",
    "   - Covenant breach tracking\n",
    "   - Sector-size normalization\n",
    "\n",
    "2. **Model Quality**\n",
    "   - Handles class imbalance with `scale_pos_weight`\n",
    "   - Isotonic calibration for reliable probabilities\n",
    "   - SHAP for transparency and trust\n",
    "\n",
    "3. **Business Integration**\n",
    "   - Clear tier definitions aligned with risk appetite\n",
    "   - Actionable recommendations for RM team\n",
    "   - Monthly scoring cadence\n",
    "   - Customer-level explanations\n",
    "\n",
    "4. **Code Quality**\n",
    "   - Modular design (separate scripts for each stage)\n",
    "   - Type hints and documentation\n",
    "   - CLI interfaces for all scripts\n",
    "   - Cookiecutter-data-science template\n",
    "\n",
    "---\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "**Model Performance:**\n",
    "- ✅ AUC-ROC ≥ 0.75\n",
    "- ✅ PR-AUC ≥ 0.40\n",
    "- ✅ KS ≥ 0.35\n",
    "- ✅ Brier Score ≤ 0.10\n",
    "\n",
    "**Business Impact:**\n",
    "- ✅ Early identification of high-risk customers\n",
    "- ✅ Reduction in unexpected defaults\n",
    "- ✅ Efficient RM resource allocation\n",
    "- ✅ Regulatory compliance (Basel, IFRS 9)\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Validation:** Run on real historical data\n",
    "2. **Backtesting:** Validate predictions against actual defaults\n",
    "3. **Integration:** Connect to core banking system for live data feeds\n",
    "4. **Monitoring:** Set up drift detection and performance tracking\n",
    "5. **Iteration:** Refine features and model based on feedback\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook serves as the complete documentation for the Corporate Credit EWS project.**  \n",
    "**For hands-on experimentation, run the pipeline commands in your terminal or create interactive cells below.**\n",
    "\n",
    "🚀 **Happy modeling!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
