<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>validation_report_en</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="VALIDATION_REPORT_EN_files/libs/clipboard/clipboard.min.js"></script>
<script src="VALIDATION_REPORT_EN_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="VALIDATION_REPORT_EN_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="VALIDATION_REPORT_EN_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="VALIDATION_REPORT_EN_files/libs/quarto-html/popper.min.js"></script>
<script src="VALIDATION_REPORT_EN_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="VALIDATION_REPORT_EN_files/libs/quarto-html/anchor.min.js"></script>
<link href="VALIDATION_REPORT_EN_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="VALIDATION_REPORT_EN_files/libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="VALIDATION_REPORT_EN_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="VALIDATION_REPORT_EN_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="VALIDATION_REPORT_EN_files/libs/bootstrap/bootstrap-9e3ffae467580fdb927a41352e75a2e0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="independent-validation-report" class="level1">
<h1>Independent Validation Report</h1>
<section id="corporate-credit-early-warning-system-ews" class="level2">
<h2 class="anchored" data-anchor-id="corporate-credit-early-warning-system-ews">Corporate Credit Early Warning System (EWS)</h2>
<p><strong>Document Information</strong><br>
<strong>Model</strong>: Corporate Credit Early Warning System (12-month horizon)<br>
<strong>Date</strong>: October 1, 2025<br>
<strong>Purpose</strong>: Independent validation before production deployment</p>
<hr>
</section>
<section id="executive-summary" class="level2">
<h2 class="anchored" data-anchor-id="executive-summary">1. Executive Summary</h2>
<p><strong>Conclusion: APPROVED (with conditions)</strong></p>
<section id="overall-assessment" class="level3">
<h3 class="anchored" data-anchor-id="overall-assessment">Overall Assessment</h3>
<p><strong>Risk Classification Ability (Good)</strong></p>
<ul>
<li>Model correctly distinguishes <strong>82.3%</strong> of high-risk vs.&nbsp;low-risk customers (scale 0-100%, higher is better)</li>
<li><strong>60% of all defaults</strong> are caught in the top 10% riskiest customers</li>
<li><strong>Stable performance</strong> across 18 months of testing, no degradation observed</li>
</ul>
<p><strong>Prediction Accuracy (Acceptable)</strong></p>
<ul>
<li>Error rate: <strong>1.26%</strong> (meaning 98.74% accurate)</li>
<li>Average difference between predicted vs.&nbsp;actual: <strong>12.8 basis points</strong> (good)</li>
<li>Some groups slightly over/under-predicted but not materially impactful</li>
</ul>
<p><strong>Alert Thresholds &amp; Operational Capacity (Feasible)</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 14%">
<col style="width: 10%">
<col style="width: 18%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Level</th>
<th>Threshold</th>
<th>Alert %</th>
<th>Precision</th>
<th>Recall</th>
<th>Alerts/Month</th>
<th>Staff Needed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Amber</strong></td>
<td>2.0%</td>
<td>8.3%</td>
<td>9.6%</td>
<td>57.5%</td>
<td>830</td>
<td>~5 people</td>
</tr>
<tr class="even">
<td><strong>Red</strong></td>
<td>5.0%</td>
<td>4.2%</td>
<td>16.3%</td>
<td>48.2%</td>
<td>421</td>
<td>~10 people</td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td>—</td>
<td>8.3%</td>
<td>—</td>
<td>57.5%</td>
<td><strong>830</strong></td>
<td><strong>~15 people</strong></td>
</tr>
</tbody>
</table>
<p><strong>Explanation:</strong></p>
<ul>
<li><strong>Amber</strong>: Customers with default risk ≥ 2% → need quarterly monitoring</li>
<li><strong>Red</strong>: Customers with default risk ≥ 5% → need immediate review (Red is subset of Amber)</li>
<li><strong>Low precision</strong> (Red 16% = out of 6 alerts, 1 is real default, 5 are false alarms)</li>
<li><strong>Catches 57.5%</strong> = detects over half of defaults, but <strong>misses 42.5%</strong> (need supplementary periodic review)</li>
<li>✓ Workload is manageable: 15 people can handle vs.&nbsp;20 available staff</li>
</ul>
<p><strong>Risks &amp; Mitigation</strong></p>
<ol type="1">
<li><strong>Test data is synthetic</strong> (no real-world noise) → <strong>Run 6-month pilot</strong> with real data</li>
<li><strong>High false alarm rate</strong> (90% of Amber alerts are false, 84% of Red are false) → <strong>Review thresholds</strong> after 6 months</li>
<li><strong>Misses 42.5% of defaults</strong> → Combine with quarterly credit review for all customers</li>
<li><strong>Not tested by segment</strong> → Analyze industry/grade performance in first 3 months</li>
</ol>
<hr>
</section>
</section>
<section id="data-methodology" class="level2">
<h2 class="anchored" data-anchor-id="data-methodology">2. Data &amp; Methodology</h2>
<section id="target-population-objective" class="level3">
<h3 class="anchored" data-anchor-id="target-population-objective">2.1 Target Population &amp; Objective</h3>
<ul>
<li><strong>Population</strong>: Corporate customers (all industries, grades A–G, with outstanding credit)</li>
<li><strong>Test data</strong>: 180,000 samples (18 months × 10,000 customers/month, Jan 2024 – Jun 2025)</li>
<li><strong>Prediction target</strong>: Probability of default within 12 months (90+ days delinquent or NPL classification)</li>
<li><strong>Actual default rate</strong>: 1.37% (i.e., 137 defaults / 10,000 customers)</li>
</ul>
</section>
<section id="model-description" class="level3">
<h3 class="anchored" data-anchor-id="model-description">2.2 Model Description</h3>
<ul>
<li><strong>Model type</strong>: Machine learning risk classifier (LightGBM)</li>
<li><strong>Input features</strong>: 20 financial metrics + payment behavior:
<ul>
<li>Top 3 most important: Days past due (recent), Debt/EBITDA ratio, Interest coverage ratio</li>
<li>Account for 45% of model influence</li>
</ul></li>
<li><strong>Calibration</strong>: Probability adjustment for better accuracy (Isotonic regression)</li>
<li><strong>Explainability</strong>: Each alert includes 3 main drivers explaining why customer is risky</li>
</ul>
</section>
<section id="data-quality-limited-due-to-synthetic-data" class="level3">
<h3 class="anchored" data-anchor-id="data-quality-limited-due-to-synthetic-data">2.3 Data Quality (Limited due to synthetic data)</h3>
<ul>
<li><strong>Missing data</strong>: 0% (synthetic), <strong>needs real-world verification</strong> (requirement &lt; 10% missing)</li>
<li><strong>Outliers</strong>: Normalized by industry scale</li>
<li><strong>Limitation</strong>: Test data is too perfect (no delays, errors like real data). <strong>First 3 months of production are critical</strong> for validation.</li>
</ul>
<hr>
</section>
</section>
<section id="validation-results" class="level2">
<h2 class="anchored" data-anchor-id="validation-results">3. Validation Results</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="plots/validation_dashboard.png" class="img-fluid figure-img"></p>
<figcaption>Validation Dashboard</figcaption>
</figure>
</div>
<section id="risk-discrimination-ability" class="level3">
<h3 class="anchored" data-anchor-id="risk-discrimination-ability">3.1 Risk Discrimination Ability</h3>
<p><strong>AUC Score (Area Under ROC Curve)</strong></p>
<ul>
<li><strong>Average</strong>: 82.3% (good, minimum threshold 75%, target 80%)</li>
<li><strong>Range</strong>: 79.2% to 85.9% (across 18 test months)
<ul>
<li>Best month: 85.9% (Aug 2024)</li>
<li>Worst month: 79.2% (May 2024)</li>
</ul></li>
<li><strong>Trend</strong>: Stable, no degradation over 18 months</li>
</ul>
<p><strong>Explanation</strong>: Score of 82.3% means the model correctly ranks high-risk vs.&nbsp;low-risk customers 82.3% of the time. This is GOOD for early warning systems (industry typically accepts &gt; 75%).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="plots/auc_ks_trend.png" class="img-fluid figure-img"></p>
<figcaption>AUC and KS Trend Over Time</figcaption>
</figure>
</div>
</section>
<section id="prediction-accuracy" class="level3">
<h3 class="anchored" data-anchor-id="prediction-accuracy">3.2 Prediction Accuracy</h3>
<p><strong>Overall Error Rate (Brier Score)</strong></p>
<ul>
<li><strong>Average</strong>: 1.26% error (meaning 98.74% accurate)</li>
<li><strong>Range</strong>: 1.06% to 1.44%</li>
<li><strong>Assessment</strong>: Very good (acceptable threshold is &lt; 2%)</li>
</ul>
<p><strong>Detailed Accuracy by Risk Group (Decile Calibration)</strong></p>
<p>Divide 10,000 customers into 10 groups by risk score:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 27%">
<col style="width: 24%">
<col style="width: 18%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Group</th>
<th>Predicted Default</th>
<th>Actual Default</th>
<th>Difference</th>
<th>Assessment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1 (lowest risk)</td>
<td>0.056%</td>
<td>0.078%</td>
<td>+0.02%</td>
<td>✓ Accurate</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.239%</td>
<td>0.117%</td>
<td>−0.12%</td>
<td>Slightly over-predicted</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.361%</td>
<td>0.472%</td>
<td>+0.11%</td>
<td>Slightly under-predicted</td>
</tr>
<tr class="even">
<td>4-5</td>
<td>0.5-0.6%</td>
<td>0.5-0.6%</td>
<td>±0.07%</td>
<td>✓ Accurate</td>
</tr>
<tr class="odd">
<td>6</td>
<td>0.648%</td>
<td>0.489%</td>
<td>−0.16%</td>
<td>Slightly over-predicted</td>
</tr>
<tr class="even">
<td>7-8</td>
<td>0.7-0.9%</td>
<td>0.8-0.9%</td>
<td>±0.04%</td>
<td>✓ Accurate</td>
</tr>
<tr class="odd">
<td>9</td>
<td>1.173%</td>
<td>0.917%</td>
<td>−0.26%</td>
<td>Slightly over-predicted</td>
</tr>
<tr class="even">
<td>10 (highest risk)</td>
<td>7.92%</td>
<td>8.83%</td>
<td>+0.91%</td>
<td>Slightly under-predicted</td>
</tr>
</tbody>
</table>
<p><strong>Observations</strong>:</p>
<ul>
<li><strong>Average error</strong>: 0.128% (acceptable, threshold &lt; 0.20%)</li>
<li><strong>Highest risk group</strong> (Group 10): Predicts 0.91% lower than actual → Model is slightly <strong>conservative</strong> (tends to predict less than reality). This is <strong>acceptable</strong> for early warning (better to miss some than over-alert).</li>
<li><strong>Groups 2, 6, 9</strong>: Over-predict by 0.12-0.26% → May cause some false alerts but within tolerance.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="plots/decile_calibration.png" class="img-fluid figure-img"></p>
<figcaption>Calibration by Decile</figcaption>
</figure>
</div>
</section>
<section id="risk-concentration-ability" class="level3">
<h3 class="anchored" data-anchor-id="risk-concentration-ability">3.3 Risk Concentration Ability</h3>
<ul>
<li><strong>Top 10% riskiest customers</strong> → Catch <strong>60% of all defaults</strong></li>
<li><strong>Top 20% riskiest customers</strong> → Catch <strong>70% of all defaults</strong></li>
<li><strong>Top 8% customers (Amber threshold at 2%)</strong> → Catch <strong>57.5% of defaults</strong></li>
</ul>
<p><strong>Explanation</strong>: Model concentrates risk very well. Only need to monitor 8% of customers (830/month) to catch over half of defaults → Workload is feasible.</p>
<hr>
</section>
</section>
<section id="stability-drift" class="level2">
<h2 class="anchored" data-anchor-id="stability-drift">4. Stability &amp; Drift</h2>
<section id="data-stability-psi" class="level3">
<h3 class="anchored" data-anchor-id="data-stability-psi">4.1 Data Stability (PSI)</h3>
<ul>
<li><strong>PSI = 0.00</strong> across all 18 test months (too perfect due to synthetic data)</li>
<li><strong>Real-world validation needed</strong>: Use <strong>first 3 months of production</strong> to establish real PSI baseline</li>
<li><strong>Alert thresholds</strong>:
<ul>
<li>PSI &gt; 0.10 → Monitor (data starting to change)</li>
<li>PSI &gt; 0.25 → Mandatory recalibration</li>
</ul></li>
</ul>
<p><strong>PSI Explanation</strong>: Measures how much customer characteristics change over time. High PSI = data changed a lot → need to recalibrate model.</p>
</section>
<section id="performance-trend" class="level3">
<h3 class="anchored" data-anchor-id="performance-trend">4.2 Performance Trend</h3>
<ul>
<li><strong>AUC score</strong> fluctuated from 83.4% (Q1/2024) down to 81.9% (Q2/2025)</li>
<li>Difference of −1.5% <strong>is within acceptable range</strong> (no severe degradation observed)</li>
<li><strong>No trigger</strong> for recalibration (AUC &gt; 75% consistently)</li>
</ul>
<hr>
</section>
</section>
<section id="alert-thresholds-operational-capacity" class="level2">
<h2 class="anchored" data-anchor-id="alert-thresholds-operational-capacity">5. Alert Thresholds &amp; Operational Capacity</h2>
<section id="selected-thresholds" class="level3">
<h3 class="anchored" data-anchor-id="selected-thresholds">5.1 Selected Thresholds</h3>
<p><strong>Amber Alert</strong> = Default risk ≥ <strong>2.0%</strong><br>
<strong>Red Alert</strong> = Default risk ≥ <strong>5.0%</strong> (Red is subset of Amber)</p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 17%">
<col style="width: 17%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 9%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Threshold</th>
<th>Default Risk</th>
<th>Alerts/Month</th>
<th>% of Total</th>
<th>Precision</th>
<th>Recall</th>
<th>Assessment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Amber</strong></td>
<td>≥ 2.0%</td>
<td>830</td>
<td>8.3%</td>
<td>9.6%</td>
<td>57.5%</td>
<td>✓ Acceptable</td>
</tr>
<tr class="even">
<td><strong>Red</strong></td>
<td>≥ 5.0%</td>
<td>421</td>
<td>4.2%</td>
<td>17.3%</td>
<td>52.7%</td>
<td>✓ Priority</td>
</tr>
</tbody>
</table>
<p><strong>Metric Explanations:</strong></p>
<ul>
<li><strong>Precision</strong>: Out of all customers flagged, what % actually default
<ul>
<li>Amber 9.6%: Out of 10 alerts, ~1 is correct (9 are false alarms) → High false alarm rate but acceptable for early warning</li>
<li>Red 17.3%: Out of 6 alerts, ~1 is correct (5 are false alarms) → Lower false alarm rate</li>
</ul></li>
<li><strong>Recall</strong>: Out of all actual defaults, what % are caught
<ul>
<li>Amber 57.5%: Catches over half of defaults (misses 42.5%)</li>
<li>Red 52.7%: Catches over half of defaults (misses 47.3%)</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="plots/precision_recall_curve.png" class="img-fluid figure-img"></p>
<figcaption>Precision-Recall Curve</figcaption>
</figure>
</div>
</section>
<section id="operational-capacity" class="level3">
<h3 class="anchored" data-anchor-id="operational-capacity">5.2 Operational Capacity</h3>
<ul>
<li><strong>Monthly workload</strong>:
<ul>
<li>Amber alerts: <strong>830 customers</strong> (manageable with 2-3 relationship managers)</li>
<li>Red alerts: <strong>421 customers</strong> (highest priority)</li>
</ul></li>
<li><strong>Overload threshold</strong>: If &gt; 1,000 alerts/month → Need to raise Amber threshold to 2.5% or 3%</li>
</ul>
</section>
<section id="alternative-threshold-comparison" class="level3">
<h3 class="anchored" data-anchor-id="alternative-threshold-comparison">5.3 Alternative Threshold Comparison</h3>
<p>Tested 20 threshold levels from 0.5% to 10%:</p>
<ul>
<li><strong>If lower to 1.0%</strong>: 1,200 alerts/month → <strong>Overload</strong>, not feasible</li>
<li><strong>If raise to 3.0%</strong>: 620 alerts/month → Recall drops to 50% (misses too many)</li>
<li><strong>2.0% threshold is optimal</strong> balance between detection (57.5%) and workload (830 customers)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="plots/alert_volume_vs_threshold.png" class="img-fluid figure-img"></p>
<figcaption>Alert Volume vs Threshold</figcaption>
</figure>
</div>
<hr>
</section>
</section>
<section id="regulatory-compliance" class="level2">
<h2 class="anchored" data-anchor-id="regulatory-compliance">6. Regulatory Compliance</h2>
<p><strong>Requirements Met:</strong></p>
<ul>
<li><strong>Independent validation</strong>: Performed by independent Validation team (not involved in model development)</li>
<li><strong>Separate test data</strong>: 18-month test period (Jan 2024-Jun 2025) completely separate from training</li>
<li><strong>Complete documentation</strong>: Source code, data, procedures archived with version control (SHA256 hash)</li>
<li><strong>Performance thresholds</strong>: AUC &gt; 75%, Brier &lt; 2% (requirements met)</li>
<li><strong>Clear explanations</strong>: Each alert includes 3 main reason codes (SHAP-based)</li>
<li><strong>Monitoring plan</strong>: Monthly PSI, AUC tracking with clear trigger thresholds</li>
</ul>
<p><strong>Supporting Documentation:</strong></p>
<ul>
<li>Source code: <code>src/modeling/</code>, <code>src/calibrate.py</code>, <code>src/scoring.py</code></li>
<li>Data: <code>data/processed/portfolio_scored.csv</code> (180,000 records)</li>
<li>Validation report: This file + charts in <code>artifacts/validation/plots/</code></li>
</ul>
<hr>
</section>
<section id="post-deployment-monitoring" class="level2">
<h2 class="anchored" data-anchor-id="post-deployment-monitoring">7. Post-Deployment Monitoring</h2>
<p><strong>Monitoring Frequency:</strong> Monthly (after real results available)</p>
<p><strong>Key Metrics to Track:</strong></p>
<ul>
<li><strong>PSI (Stability)</strong>:
<ul>
<li>PSI &gt; 0.10 → Warning (data starting to change)</li>
<li>PSI &gt; 0.25 → Mandatory immediate recalibration</li>
</ul></li>
<li><strong>AUC (Classification Ability)</strong>:
<ul>
<li>AUC &lt; 75% for 2 consecutive months → Recalibrate</li>
<li>AUC drops &gt; 5% from baseline → Investigate root cause</li>
</ul></li>
<li><strong>Alert Rate</strong>:
<ul>
<li>Alert rate &gt; 15% → Overload warning (need to raise threshold)</li>
<li>Alert rate &lt; 5% → Threshold too high (may miss too many)</li>
</ul></li>
<li><strong>Actual Precision</strong> (after 12 months):
<ul>
<li>Compare expected precision (9.6%) with actual</li>
<li>If difference &gt; 30% → Recalibration needed</li>
</ul></li>
</ul>
<p><strong>Monitoring Tools:</strong></p>
<ul>
<li>Automated script: <code>src/run_monitoring.py</code> (run monthly)</li>
<li>Dashboard: See <code>artifacts/monitoring/</code> (PSI, AUC, alert trends)</li>
</ul>
<hr>
</section>
<section id="validators-opinion" class="level2">
<h2 class="anchored" data-anchor-id="validators-opinion">8. Validator’s Opinion</h2>
<section id="overall-conclusion" class="level3">
<h3 class="anchored" data-anchor-id="overall-conclusion">8.1 Overall Conclusion</h3>
<p><strong>✅ MODEL APPROVED FOR DEPLOYMENT</strong></p>
<p><strong>Reasons:</strong></p>
<ul>
<li>Good performance: AUC 82.3%, Brier 1.26% (exceeds minimum requirements)</li>
<li>Reasonable balance: Detects 57.5% of defaults with 830 alerts/month (feasible)</li>
<li>Stable over 18 months: No degradation observed</li>
<li>Regulatory compliance: Complete documentation, independent validation</li>
</ul>
</section>
<section id="deployment-conditions" class="level3">
<h3 class="anchored" data-anchor-id="deployment-conditions">8.2 Deployment Conditions</h3>
<p><strong>Mandatory:</strong></p>
<ol type="1">
<li><strong>Establish PSI baseline</strong> in first 3 months of production (current test data too perfect)</li>
<li><strong>Monthly monitoring</strong>: PSI, AUC, alert rate (per Section 7)</li>
<li><strong>12-month review</strong>: Compare actual vs.&nbsp;expected precision/recall</li>
</ol>
<p><strong>Recommendations:</strong></p>
<ul>
<li>Start with Amber threshold at 2% for first 6 months</li>
<li>If overloaded (&gt; 1,000 alerts/month) → Raise to 2.5% or 3%</li>
<li>Monitor Group 10 (highest risk) closely: Model predicts 0.91% lower than actual → May need calibration adjustment for tail risk</li>
</ul>
</section>
<section id="remaining-risks" class="level3">
<h3 class="anchored" data-anchor-id="remaining-risks">8.3 Remaining Risks</h3>
<p><strong>Synthetic test data risk:</strong> * PSI = 0.00 (too perfect) → Needs real-world validation * Stress test uses hard-coded data → Need to retest with real shock scenarios</p>
<p><strong>Low precision risk (9.6%):</strong> * High false alarm rate (9 false / 1 true) → May overload relationship managers if not managed well * Mitigation: Clear workflow assignment, prioritize Red before Amber</p>
<p><strong>Missed detection risk (42.5%):</strong> * Misses 42.5% of defaults (not alerted) → Credit risk still exists * Mitigation: Combine with other risk management measures (periodic review, human judgment)</p>
<hr>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>